# Récupération des données SST

## Chargement de packages nécessaires

-   `httr` pour le téléchargement des fichiers de données
-   `tidyverse` pour les fonctionnalités offertes par
    1.  `ggplot2`,
    2.  `lubridate` pour la gestion du temps,
    3.  `purrr`, entre autres.
-   `terra`,
-   `ncdf4` pour la gestion des fichiers NetCDF,
-   `stringi` pour la fonction stri_sub 

```{r}
#| label: load_libraries
#| message: false

libs <- c("glue", "httr", "tidyverse", "terra", "ncdf4", "stringi", "gt")

#install missing libraries
installed_libs <- libs %in% rownames(installed.packages())
if (any(installed_libs == FALSE)) {
  install.packages(libs[!installed_libs])
}

#load libraries
invisible(lapply(libs, library, character.only = TRUE))

```

## Décompte des fichiers exploitables 

Les fichiers de données NectCDF temporaires ont le suffixe "\_preliminary".   
Les autres ne possèdent pas ce suffixe.

Le premier fichier NetCDF exploitable date du 1er septembre 1981. 
En date du `Sys.Date()` nous allons déterminer :

- la date du dernier fichier finalisé disponible
- la date du dernier fichier temporaire disponible
- le nombre total de fichiers finalisés
- le nombre total de fichiers temporaires

```{r}
#| label: tools

yyyymm <- function(date) {
  return(gsub("-", "", stri_sub(date, 1, 7)))
}

yyyymmdd <- function(date) { 
  return(gsub("-", "", date))
}
```

### Détermination de l'url du fichier de données `.nc` 

- en fonction de la date,
- et du statut (finalisé ou temporaire)

```{r}
#| label: get_url

get_url <- function(date, is.preliminary = FALSE) {
  
  url_root <- "https://www.ncei.noaa.gov/data/sea-surface-temperature-optimum-interpolation/v2.1/access/avhrr"
  url_folder <- paste(url_root, yyyymm(date), sep = "/")
  file_prefix <- "oisst-avhrr-v02r01."
  file_suffix <- if_else(is.preliminary, "_preliminary.nc", ".nc")
  url_file <- paste0(file_prefix, yyyymmdd(date), file_suffix)
  return(paste(url_folder, url_file, sep = '/'))
  
}

get_all_url <- function(start_date, end_date, is.preliminary = FALSE) {
  
  seq_days <- seq(start_date, end_date, by = "days")
  all_url <- sapply(seq_days, get_url, is.preliminary = is.preliminary)
  return(all_url)
  
}

```

### Détermination des dates les plus récentes pour les fichiers `.nc`

Principe :

On recherche à partir de la date du jour la présence des données aux urls que l'on aura calculées par ailleurs avec la fonction `get_url`.
Si la page sollicitée est présente on a fini. Sinon on passe au jour précédent.

```{r}
#| label: get_latest_date
#| 
get_latest_date <- function(init_date, increment = -1, is.preliminary) {
  
  date <- init_date
  http_200_status_OK <- FALSE
  while (!http_200_status_OK) {
    url <- get_url(date = date, is.preliminary = is.preliminary)
    http_status_code <- status_code(GET(url))
    if (http_status_code == 404) { 
      date <- date + increment
    } else {
      if (http_status_code == 200) { 
        http_200_status_OK <- TRUE 
      }
    }
  }
  return(date)
}

latest_preliminary_date <- get_latest_date(
  init_date = Sys.Date(),
  is.preliminary = TRUE
)

latest_finalized_date <- get_latest_date(
  init_date = Sys.Date() - 14,
  is.preliminary = FALSE
)

```

::: {.callout-note}

Si des fichiers `preliminary` se retrouvent encore parmi des fichiers finalisés, parce qu'ils n'auront pas encore été traités, alors les décomptes de fichiers finalisés et temporaires seront inexacts.

:::

```{r}
#| label: get_data_files_count
#| 
data_files_count <- function(start_date, end_date) {
  
  lubridate::interval(start_date, end_date) %/% days(1) + 1

}

nc_files_count <- data_files_count(ymd("1981-09-01"), latest_finalized_date)
preliminary_files_count <- data_files_count(ymd("1981-09-01"), latest_preliminary_date)

tib_summary <- tibble(
  file_extension = c(".nc", "_preliminary.nc"),
  file_type = c("Finalisé", "Temporaire"),
  latest_date = c(latest_finalized_date, latest_preliminary_date),
  file_count  = c(nc_files_count, preliminary_files_count)
)

gt_summary <- gt(tib_summary) |> 
  tab_header(
    title = md("**Informations relatives aux fichiers de données**"),
    subtitle = md("*(Les dates sont estimées)*")
  )
gt_summary

```

## Remplissage de la table des fichiers de données

Création d'un tibble `tib_sst` composée des colonnes suivantes :

- date : date de récupération des données
- data_filename : nom local du fichier de données
- data_url : url permettant d'accéder aux données pour une date donnée

::: {.callout-note}

La problématique consiste à mettre à jour au fil de l'eau les données qui sont initialement enregistrées dans un fichier avec l'extension **preliminary.nc" le temps que les données soient "validées". Cette opération se déroule sur un délai d'approximativement 2 semaines à partir de la récupération des données.

:::

Le fichier `tib_expected` contient les informations relatives à l'ensemble des données théoriquement entreposées sur le serveur.

```{r}
#| label: tib_expected
#| code-fold: true
#| 
# remplissage du champ date

tib_expected <- tibble(
  date = seq(ymd("1981-09-01"), latest_preliminary_date, by = "days")
)

# remplissage du champ data_url

url_finalized_data <- get_all_url(
  start_date = ymd("1981-09-01"),
  end_date = latest_finalized_date,
  is.preliminary = FALSE
)
  
url_preliminary_data <- get_all_url(
  start_date = latest_finalized_date + 1,
  end_date = latest_preliminary_date,
  is.preliminary = TRUE
)

tib_expected$data_url <- c(url_finalized_data, url_preliminary_data)

# remplissage du champ data_filename

tib_expected$data_filename <- tib_expected$data_url |>
  map(\(x) {tail(stri_split_fixed(x, "/")[[1]], n = 1)}) |> 
  unlist()

```

Le champ data_files_loaded de type logique permet de connaître la liste des fichiers de données déjà présents dans le dossier `DATA/RAW`

```{r}
#| label: is_data_expected_loaded
#| 
# data_loaded renseigne sur la présence du fichier en local (dossier DATA/RAW)

data_files <- tib_expected$data_filename
data_files_loaded <- list.files(path = "DATA/RAW", pattern = "*.nc*")
data_preliminary_loaded <- list.files(
  path = "DATA/RAW", pattern = "*_preliminary.nc*"
)
tib_expected$data_loaded <- (data_files %in% data_files_loaded)

```


```{r}
#| label: delete_preliminary_data

data_files_to_delete <- data_files_loaded[!(data_files_loaded %in% data_files)]
if (length(data_files_to_delete > 0)) {
  unlink(paste("DATA/RAW", data_files_to_delete, sep = "/"))
}

```

## Téléchargement des données SST (si nécessaire avec data_loaded == FALSE)

```{r}
#| label: data_download
#| message: false

get_unloaded_data <- function(data_filename, data_url) {
  
  file_path <- paste("DATA/RAW" , data_filename, sep = "/")
  status_code <- status_code(GET(data_url))
  message(status_code)
  if (status_code == 200) {
    res <- httr::GET(data_url,
                     write_disk(file_path, overwrite = TRUE),
                     progress()
                    )
  } else {
    message(glue("The data for file {data_filename} are inaccessible"))
  }
  
}

data_files_unloaded <- tib_expected |> 
  dplyr::filter(!data_loaded)
data_filenames <- data_files_unloaded$data_filename
data_urls <- data_files_unloaded$data_url
pwalk(list(data_filenames, data_urls), get_unloaded_data)

```


```{r}
#| label: get_data_state_after_download_and_save
#| 
# data_loaded renseigne sur la présence du fichier en local (dossier DATA)

tib_sst <- tib_expected
data_files <- tib_sst$data_filename
data_files_loaded <- list.files(path = "DATA/RAW", pattern = "*.nc*")
tib_sst$data_loaded <- (data_files %in% data_files_loaded)

saveRDS(tib_sst, "DATA/tib_sst.RDS")

```

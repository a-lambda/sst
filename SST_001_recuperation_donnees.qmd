# Récupération des données SST

## Chargement de packages nécessaires

-   `httr` pour le téléchargement des fichiers de données
-   `tidyverse` pour les fonctionnalités offertes par
    1.  `ggplot2`,
    2.  `lubridate` pour la gestion du temps,
    3.  `purrr`, entre autres.
-   `terra`,
-   `ncdf4` pour la gestion des fichiers NetCDF,
-   `stringi` pour la fonction stri_sub 

```{r}
#| label: load_libraries
#| message: false

libs <- c(
  "glue",
  "httr",
  "tidyverse",
  "terra",
  "ncdf4",
  "stringi"
)

#install missing libraries
installed_libs <- libs %in% rownames(installed.packages())
if (any(installed_libs == FALSE)) {
  install.packages(libs[!installed_libs])
}

#load libraries
invisible(lapply(libs, library, character.only = TRUE))

```

## Décompte des fichiers exploitables 

Les fichiers de données NectCDF temporaires ont le suffixe "\_preliminary".   
Les autres ne possèdent pas ce suffixe.

Le premier fichier NetCDF exploitable date du 1er septembre 1981. 
En date du `Sys.Date()` nous allons déterminer :

- la date du dernier fichier finalisé disponible
- la date du dernier fichier temporaire disponible
- le nombre total de fichiers finalisés
- le nombre total de fichiers temporaires

```{r}
#| label: tools

yyyymm <- function(date) {
  return(gsub("-", "", stri_sub(date, 1, 7)))
}

yyyymmdd <- function(date) { 
  return(gsub("-", "", date))
}
```


```{r}
#| label: url_data

url_data <- function(date, is.preliminary = FALSE) {
  
  url_root <- "https://www.ncei.noaa.gov/data/sea-surface-temperature-optimum-interpolation/v2.1/access/avhrr"
  file_prefix <- "oisst-avhrr-v02r01." 
  file_suffix <- ifelse(is.preliminary, "_preliminary.nc", ".nc")
  return(
    paste(
      url_root, 
      yyyymm(date),
      paste0(file_prefix, yyyymmdd(date), file_suffix),
      sep = "/"  
    )
  )
  
}

```


```{r}
#| label: get_newest_date
#| 
get_newest_date <- function(is.preliminary) {
  
  init_date <- as.Date(
    ifelse(is.preliminary, Sys.Date(), Sys.Date() - 14)
  )
  date <- init_date
  http_200_status_OK <- FALSE
  while (!http_200_status_OK) {
    url <- url_data(date = date, is.preliminary = is.preliminary)
    http_status_code <- status_code(
      GET(url)
    )
    if (http_status_code == 404) { 
      date <- date - 1
    } else {
      if (http_status_code == 200) { 
        http_200_status_OK <- TRUE 
      }
    }
  }
  return(date)
}

newest_preliminary_date <- get_newest_date(is.preliminary = TRUE)
newest_finalized_date <- get_newest_date(is.preliminary = FALSE)

```


```{r}
#| label: get_data_files_count
#| 
data_files_count <- function(start_date, end_date) {
  
  lubridate::interval(start_date, end_date) %/% days(1) + 1

}

nc_files_count <- data_files_count(ymd("1981-09-01"), newest_finalized_date)
preliminary_files_count <- data_files_count(ymd("1981-09-01"), newest_preliminary_date)

paste0("Dernier fichier finalisé daté du : ", newest_finalized_date)
paste0("Dernier fichier temporaire daté du : ", newest_preliminary_date)
paste0("Nombre de fichiers finalisés : ", nc_files_count)
paste0("Nombre de fichiers temporaires : ", preliminary_files_count)

```

## Remplissage de la table des fichiers de données

Création d'un tibble `tib_sst` composée des colonnes suivantes :

- date : date de récupération des données
- data_filename : nom local du fichier de données
- data_url : url permettant d'accéder aux données pour une date donnée

Remarque :

La problématique consiste à mettre à jour au fil de l'eau les données qui sont initialement enregistrées dans un fichier avec l'extension **preliminary.nc" le temps que les données soient "validées". Cette opération se déroule sur un délai d'approximativement 2 semaines à partir de la récupération des données.

```{r}
#| label: tib_expected

# Les mesures ont démarré le 1er septembre 1981
# 
tib_expected <- tibble(
  date = seq(ymd("1981-09-01"), newest_preliminary_date, by = "days")
)

get_data_url <- function(start_date, end_date, is.preliminary) {
  
  seq_days <- seq(start_date, end_date, by = "days")
  url_folder <- yyyymm(seq_days)
  file_prefix <- "oisst-avhrr-v02r01."
  file_suffix <- if_else(is.preliminary, "_preliminary.nc", ".nc")
  url_file <- paste0(file_prefix, yyyymmdd(seq_days), file_suffix)
  return(list(url_folder, url_file))
  
}
  
url_finalized_data <- get_data_url(
  start_date = ymd("1981-09-01"),
  end_date = newest_finalized_date,
  is.preliminary = FALSE
)
  
url_preliminary_data <- get_data_url(
  start_date = newest_finalized_date + 1,
  end_date = newest_preliminary_date,
  is.preliminary = TRUE
)

tib_expected$data_filename <- c(
  url_finalized_data[[2]], 
  url_preliminary_data[[2]]
)

url_root <- "https://www.ncei.noaa.gov/data/sea-surface-temperature-optimum-interpolation/v2.1/access/avhrr/"
  
get_data_urls <- function(url_parts) {
  
  return(paste(url_root, url_parts[[1]], url_parts[[2]], sep = "/"))
         
} 

tib_expected$data_url <- c(
  get_data_urls(url_finalized_data),
  get_data_urls(url_preliminary_data)
)

```

Le champ data_files_loaded de type logique permet de connaître la liste des fichiers de données déjà présents dans le dossier `DATA`

```{r}
#| label: is_data_expected_loaded
#| 
# data_loaded renseigne sur la présence du fichier en local (dossier DATA)

data_files <- tib_expected$data_filename
data_files_loaded <- list.files(path = "DATA", pattern = "*.nc*")
data_preliminary_loaded <- list.files(
  path = "DATA", pattern = "*_preliminary.nc*"
)
tib_expected$data_loaded <- (data_files %in% data_files_loaded)

```


```{r}
#| label: delete_preliminary_data

data_files_to_delete <- data_files_loaded[!(data_files_loaded %in% data_files)]
if (length(data_files_to_delete > 0)) {
  unlink(paste("DATA", data_files_to_delete, sep = "/"))
}

```

## Téléchargement des données SST (si nécessaire avec data_loaded == FALSE)

```{r}
#| label: data_download
#| message: false

get_unloaded_data <- function(data_filename, data_url) {
  
  file_path <- paste("DATA" , data_filename, sep = "/")
  status_code <- status_code(GET(data_url))
  message(status_code)
  if (status_code == 200) {
    res <- httr::GET(data_url,
                     write_disk(file_path, overwrite = TRUE),
                     progress()
                    )
  } else {
    message(glue("The data for file {data_filename} are inaccessible"))
  }
  
}

data_files_unloaded <- tib_expected |> 
  dplyr::filter(!data_loaded)

data_filenames <- data_files_unloaded$data_filename
data_urls <- data_files_unloaded$data_url

pwalk(list(data_filenames, data_urls), get_unloaded_data)

```


```{r}
#| label: get_data_state_after_download_and_save
#| 
# data_loaded renseigne sur la présence du fichier en local (dossier DATA)

tib_sst <- tib_expected
data_files <- tib_sst$data_filename
data_files_loaded <- list.files(path = "DATA", pattern = "*.nc*")
tib_sst$data_loaded <- (data_files %in% data_files_loaded)

saveRDS(tib_sst, "DATA/tib_sst.RDS")

```



---
title: "Données temporelles"
format: html
---

## chargement librairies utiles

```{r}
#| message: false
#| 
libs <- c(
  "ncdf4",
  "tidyverse",
  "data.table",
  "jsonlite",
  "tictoc",
  "fpp3"
)
#install missing libraries
installed_libs <- libs %in% rownames(installed.packages())
if (any(installed_libs == FALSE)) {
  install.packages(libs[!installed_libs])
}
#load libraries
invisible(lapply(libs, library, character.only = TRUE))

```

## fonctions de base (peut-être disponibles dans lubridate)

```{r}

yyyymm <- function(date) { # transform Date '1981-06-25' to string '198106' 
  annee <- year(date)
  mois <- month(date)
  paste0(annee, if_else(mois > 9, as.character(mois), paste0("0", mois)))
}

yyyymmdd <- function(date) { # transform Date '1981-06-25' to string '19810625'
  annee <- year(date)
  mois <- month(date)
  jour <- day(date)
  paste0(
    annee,
    if_else(mois > 9, as.character(mois), paste0("0", mois)),
    if_else(jour > 9, as.character(jour), paste0("0", jour))
  )
}

```

## weights to apply to square of 0.25°x0.25° along the latitude

```{r}

area_weights <- fread(
  file = "area_weights.csv",
  dec = ","
) |> pull( w )

```

## fonctions de calcul de moyenne pondérée

Le principe consiste à détecter un fichier de moyenne (fichier RDS) déjà présent ou pas.

Si ce dernier est présent il est lu et complété.

Dans le cas contraire la constition de ce fichier est réalisée à partir de tous les fichiers NetCDF contenus dans le répertoire DATA.

Si le fichier pris en compte est un fichier temporaire (suffixe _preliminary) on attribuera à la donnée un `status_ok` de valeur $FALSE$

Si le fichier pris en compte est un fichier finalisé `status_ok`vaudra $TRUE$

```{r}

# get weighted mean of one variable between lat_min and lat_max
get_var_weighted_mean <- function(file, var, lon_min, lon_max, lat_min, lat_max) {
  # are we consider preliminary file
  status_ok <- if_else(str_detect(file, '_preliminary'), FALSE, TRUE)
  #--- get data from NetCDF file
  nc <- nc_open(file)
  lon <- ncvar_get(nc, varid = "lon")
  lat <- ncvar_get(nc, varid = "lat")
  time <- ncvar_get(nc, varid = "time")
  var <- ncvar_get(nc, varid = var)
  nc_close(nc)
  #--- create the area_weights matrix
  w <- matrix(rep(area_weights, 1440), ncol = 720, byrow = TRUE)
  x_min <- min(which(lon >= lon_min))
  x_max <- max(which(lon <= lon_max))
  y_min <- min(which(lat >= lat_min))
  y_max <- max(which(lat <= lat_max))
  
  #--- calculate weighted mean
  wm_var <- weighted.mean(
    var[x_min:x_max, y_min:y_max], 
    w[x_min:x_max, y_min:y_max], 
    na.rm = TRUE
  )
  #--- 
  c(time, wm_var, status_ok)
}

# get all weighted mean for one variable for all NetCDF files available
get_var_all_weighted_mean <- function(var, lon_min, lon_max, lat_min, lat_max) {
  files <- list.files(path = "DATA", pattern = "*.nc", full.names = TRUE)
  if (length(files) > 0 ) {
    #--- RDS file format : weighted_mean_<var>_XXXS_XXXN.RDS
    RDS_file <- paste0(
      'weighted_mean_', 
      var, 
      '_', lon_min,
      '_', lon_max,
      '_', abs(lat_min), 'S',
      '_', abs(lat_max), 'N', '.RDS'
    )
    message(RDS_file)
    if (file.exists(RDS_file)) {
      #--- return valid files which mean have already been treated
      RDS_data <- readRDS(RDS_file) |> 
        filter(status_ok) # élimination des données temporaires
      saveRDS(RDS_data, RDS_file) 
      valid_files_already_treated <- RDS_data |>
        pull(date) |> 
        yyyymmdd() |> 
        vapply(\(x) paste0('DATA/oisst-avhrr-v02r01.', x, '.nc'), character(1))
      #--- return tempo files which mean have already been treated
      files_to_treat <- files[!(files %in% valid_files_already_treated)]
    } else {
      files_to_treat <- files
    }
    #--- be aware not to consider old tempo files for later version !!!
    origin_date <- ymd("1978-01-01")
    wm_matrix <- matrix(numeric(0), nrow = length(files_to_treat), ncol = 3)
    colnames(wm_matrix) <- c('time', 'wm', 'status_ok')
    for (i in seq_along(files_to_treat)) { 
      result <- get_var_weighted_mean(files_to_treat[i], var, lon_min, lon_max, lat_min, lat_max)
      message(paste0("file : ", files_to_treat[i]))
      wm_matrix[i, 1] <- result[1] # time in days from origin date
      wm_matrix[i, 2] <- result[2] # weighted mean
      wm_matrix[i, 3] <- result[3] # status
    }
    df_wm_var <- as_tibble(wm_matrix) |>
      set_names('time', paste0('wm_', var), 'status_ok') |> 
      mutate(
        date = lubridate::as_date(time, origin = origin_date),
        status_ok = as.logical(status_ok)
      )
    if (file.exists(RDS_file)) {
      RDS_data <- rbind(RDS_data, df_wm_var)
    } else {
      RDS_data <- df_wm_var
    }
    saveRDS(RDS_data, RDS_file)
    RDS_data
  } else { 
    message("aucun fichier de données à traiter") 
  }
}

```

## calcul des moyennes pondérées pour des latitutes comprises entre -60° et 60°

Les moyennes pondérées sont calculées consécutivement sur les variables :

- sst
- anom
- err
- ice

```{r}

# get weighted mean var with -60 < latitude < 60

df_wm_sst_0_360_60S_60N <- get_var_all_weighted_mean("sst", 0, 360, -60, 60)
df_wm_anom_0_360_60S_60N <- get_var_all_weighted_mean("anom", 0, 360, -60, 60)
df_wm_err_0_360_60S_60N <- get_var_all_weighted_mean("err", 0, 360, -60, 60)
df_wm_ice_0_360_60S_60N <- get_var_all_weighted_mean("ice", 0, 360, -60, 60)

```

## calcul des moyennes pondérées pour l'ensemble du globe (-90° < latitude < 90°)

Les mêmes variables que précédemment sont prises en compte.

```{r}

df_wm_sst_0_360_90S_90N <- get_var_all_weighted_mean("sst", 0, 360, -90, 90)
df_wm_anom_0_360_90S_90N <- get_var_all_weighted_mean("anom", 0, 360, -90, 90)
df_wm_err_0_360_90S_90N <- get_var_all_weighted_mean("err", 0, 360, -90, 90)
df_wm_ice_0_360_90S_90N <- get_var_all_weighted_mean("ice", 0, 360, -90, 90)

```


```{r}
#| label: json_data_comparison
#| include: false

## load official json data to compare mine with

# link <- "https://climatereanalyzer.org/clim/sst_daily/json/oisst2.1_world2_sst_day.json"
# df_wm_sst_60S_60N_json <- jsonlite::fromJSON(link)
# saveRDS(df_wm_sst_60S_60N_json, "df_wm_sst_60S_60N_json.json")
# sst_60S_60N_json <- readRDS("df_wm_sst_60S_60N_json.json") |>
#   unnest_longer(col = "data", values_to = "wm_sst", indices_to = "yday") |>
#   mutate(year = name) |> 
#   select(year, yday, wm_sst) |> 
#   filter(year %in% 1981:2024) |> # eliminate sigma and general mean data
#   mutate(year = as.integer(year)) |>
#   drop_na()
# 
# sst_60S_60N_json |> 
#   summarize(.by = year, totday = n()) -> result



# sst_join <- inner_join(
#   sst_60S_60N_json,
#   sst_60S_60N,
#   by = c("year", "yday") 
# ) |> 
#   mutate(
#     wm_sst_round = round(wm_sst.y, 2),
#     diff = wm_sst.x - wm_sst_round
#   ) 
# 
# sst_join |> 
#   filter(abs(diff) > 0) |> 
#   summarize(
#     sum_diff_neg = sum(if_else(diff < 0, diff, 0)),
#     sum_diff_pos = sum(if_else(diff > 0, diff, 0))
#   )

```

## Impression de la série temporelle 

```{r}

sst_0_360_60S_60N <- readRDS('weighted_mean_sst_0_360_60S_60N.RDS') |> 
  mutate(
    year = year(date),
    yday = yday(date),
    month = month(date)
    ) 
    
ggplot(data = sst_0_360_60S_60N,
       aes(x = yday, y = wm_sst, group = year)) +
  geom_line(aes(color = factor(year))) +
  scale_color_grey(start = 0.8, end = 0.2) +
  geom_line(
    data = sst_0_360_60S_60N |> filter(year == 2023),
    aes(x = yday, y = wm_sst),
    color = "orange",
    linewidth = 1) +
  geom_line(
    data = sst_0_360_60S_60N |> filter(year == 2024),
    aes(x = yday, y = wm_sst, group = year),
    color = "black", 
    linewidth = 1) +
  labs(
    title = "Daily Sea Surface Temperature, World (60°S-60°N, 0-360°E)",
    subtitle = "Dataset: NOAA OISST V2.1",
    caption = 'caption test',
    color = NULL,
    x = NULL,
    y = NULL
  ) -> p

p + 
  theme_bw() +
  theme(
    legend.position = "bottom",
    plot.caption = element_text(margin = margin(t = 0, unit = 'cm')),
    legend.spacing.x = unit(0.5, 'cm'),
    legend.key = element_blank(),
    legend.text = element_text(colour = 'black'),
  ) +
  guides(
    color = guide_legend(
      ncol = 7, 
      byrow = TRUE, 
      reverse = FALSE,
      label = TRUE,
      #label.hjust = 1,
      #keywidth = unit(0.8, 'cm'),
      label.position = "right",
      x.intersp = 0.2,
      text.width = 0.045
    )
  ) 

```

## impression supplémentaire 1

```{r}

ggplot(data = sst_0_360_60S_60N,
       aes(x = date, y = wm_sst)) +
  geom_line() +
  geom_smooth(
    method = "lm",
    se = FALSE
  ) + 
  geom_smooth(
    data = sst_0_360_60S_60N |> 
      filter(year > 2000),
    method = "lm",
    se = FALSE, colour = "#FFA050"
  ) +
  geom_smooth(
    data = sst_0_360_60S_60N |> 
      filter(year > 2010),
    method = "lm",
    se = FALSE, colour = "#FF0000"
  )

```

## impression supplémentaire 2
  
```{r}

sst_90S_90N <- readRDS("weighted_mean_sst_0_360_90S_90N.RDS") |> 
  mutate(year = year(date))
ggplot(data = sst_90S_90N) +
  geom_line(aes(x = date, y = wm_sst, group = year, color = year))

```


```{r}
#| label: tsibble_test
#| include: false

# ts_sst_60S_60N <- as_tsibble(sst_60S_60N)
# autoplot(ts_sst_60S_60N, wm_sst)
# gg_season(ts_sst_60S_60N, wm_sst, period = "year")

# ts_sst_90S_90N <- as_tsibble(sst_90S_90N)
# autoplot(ts_sst_90S_90N, wm_sst)
# gg_season(ts_sst_90S_90N, wm_sst)

```






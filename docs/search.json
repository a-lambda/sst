[
  {
    "objectID": "SST_001_recuperation_donnees.html",
    "href": "SST_001_recuperation_donnees.html",
    "title": "\n2  Récupération des données SST\n",
    "section": "",
    "text": "2.1 Chargement de packages nécessaires\nCodelibs &lt;- c(\"glue\", \"httr\", \"tidyverse\", \"terra\", \"ncdf4\", \"stringi\", \"gt\")\n\ninstalled_libs &lt;- libs %in% rownames(installed.packages())\nif (any(installed_libs == FALSE)) {\n  install.packages(libs[!installed_libs])\n}\n\ninvisible(lapply(libs, library, character.only = TRUE))",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Données SST</span>"
    ]
  },
  {
    "objectID": "SST_001_recuperation_donnees.html#chargement-de-packages-nécessaires",
    "href": "SST_001_recuperation_donnees.html#chargement-de-packages-nécessaires",
    "title": "\n2  Récupération des données SST\n",
    "section": "",
    "text": "httr pour le téléchargement des fichiers de données\n\ntidyverse pour les fonctionnalités offertes par\n\n\nggplot2,\n\nlubridate pour la gestion du temps,\n\npurrr, entre autres.\n\n\n\nterra,\n\nncdf4 pour la gestion des fichiers NetCDF,\n\nstringi pour la fonction stri_sub\n\ngt pour la représentation tabulaire",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Données SST</span>"
    ]
  },
  {
    "objectID": "SST_001_recuperation_donnees.html#décompte-des-fichiers-exploitables",
    "href": "SST_001_recuperation_donnees.html#décompte-des-fichiers-exploitables",
    "title": "\n2  Récupération des données SST\n",
    "section": "\n2.2 Décompte des fichiers exploitables",
    "text": "2.2 Décompte des fichiers exploitables\nLes fichiers de données NectCDF temporaires ont le suffixe “_preliminary”.\nLes autres ne possèdent pas ce suffixe.\nLe premier fichier NetCDF exploitable date du 1er septembre 1981. En date du Sys.Date() nous allons déterminer :\n\nla date du dernier fichier finalisé disponible\nla date du dernier fichier temporaire disponible\nle nombre total de fichiers finalisés\nle nombre total de fichiers temporaires\n\n\n2.2.1 Détermination de l’url du fichier de données .nc\n\n\nen fonction de la date,\net du statut (finalisé ou temporaire)\n\n\nCodeyyyymm &lt;- function(date) {\n  return(gsub(\"-\", \"\", stri_sub(date, 1, 7)))\n}\n\nyyyymmdd &lt;- function(date) { \n  return(gsub(\"-\", \"\", date))\n}\n\nget_url &lt;- function(date, is.preliminary = FALSE) {\n  \n  url_root &lt;- \"https://www.ncei.noaa.gov/data/sea-surface-temperature-optimum-interpolation/v2.1/access/avhrr\"\n  url_folder &lt;- paste(url_root, yyyymm(date), sep = \"/\")\n  file_prefix &lt;- \"oisst-avhrr-v02r01.\"\n  file_suffix &lt;- if_else(is.preliminary, \"_preliminary.nc\", \".nc\")\n  url_file &lt;- paste0(file_prefix, yyyymmdd(date), file_suffix)\n  return(paste(url_folder, url_file, sep = '/'))\n  \n}\n\nget_all_url &lt;- function(start_date, end_date, is.preliminary = FALSE) {\n  \n  seq_days &lt;- seq(start_date, end_date, by = \"days\")\n  all_url &lt;- sapply(seq_days, get_url, is.preliminary = is.preliminary)\n  return(all_url)\n  \n}\n\n\n\n2.2.2 Datation des derniers fichiers (temporaire et finalisé)\nPrincipe :\nOn recherche à partir de la date du jour la présence des données aux urls que l’on aura calculées par ailleurs avec la fonction get_url. Si la page sollicitée est présente on a fini.\nSinon on passe au jour précédent, et ainsi de suite si nécessaire, jusqu’à tomber sur un code réponse http de valeur 200.\n\n\n\n\n\n\nNote\n\n\n\nLes données collectées qualifiées de temporaires sont enregistrées dans un fichier avec l’extension _preliminary.nc le temps que les données soient vérifiées et validées.\nCette opération se déroule sur un délai d’approximativement 2 semaines à partir de la date de collecte des données.\n\n\n\nCodeget_latest_date &lt;- function(init_date, increment = -1, is.preliminary) {\n  \n  date &lt;- init_date\n  http_200_status_OK &lt;- FALSE\n  while (!http_200_status_OK) {\n    url &lt;- get_url(date = date, is.preliminary = is.preliminary)\n    http_status_code &lt;- status_code(GET(url))\n    if (http_status_code == 404) { \n      date &lt;- date + increment\n    } else {\n      if (http_status_code == 200) { \n        http_200_status_OK &lt;- TRUE \n      }\n    }\n  }\n  return(date)\n}\n\nlatest_preliminary_date &lt;- get_latest_date(\n  init_date = Sys.Date(),\n  is.preliminary = TRUE\n)\n\nlatest_finalized_date &lt;- get_latest_date(\n  init_date = Sys.Date() - 14,\n  is.preliminary = FALSE\n)\n\n\n\n\n\n\n\n\nNote\n\n\n\nSi des fichiers preliminary se retrouvent encore parmi des fichiers finalisés, parce qu’ils n’auront pas encore été traités, alors les décomptes de fichiers finalisés et temporaires seront inexacts.\n\n\n\nCodedata_files_count &lt;- function(start_date, end_date) {\n  \n  lubridate::interval(start_date, end_date) %/% days(1) + 1\n\n}\n\nnc_files_count &lt;- data_files_count(ymd(\"1981-09-01\"), latest_finalized_date)\npreliminary_files_count &lt;- data_files_count(ymd(\"1981-09-01\"), latest_preliminary_date)\n\ntib_summary &lt;- tibble(\n  file_extension = c(\".nc\", \"_preliminary.nc\"),\n  file_type = c(\"Finalisé\", \"Temporaire\"),\n  latest_date = c(latest_finalized_date, latest_preliminary_date),\n  file_count  = c(nc_files_count, preliminary_files_count)\n)\n\ngt_summary &lt;- gt(tib_summary) |&gt; \n  tab_header(\n    title = md(\"**Informations relatives aux fichiers de données**\"),\n    subtitle = md(\"(Valeurs théoriques)\")\n  ) |&gt; \n  tab_footnote(\n    footnote = md(\"Première collecte quotidienne datée du **01/09/1981**\"),\n    locations = cells_body(\n      columns = file_count, rows = all()\n    )\n  ) |&gt; \n  tab_footnote(\n    footnote = md(\"Dates **estimées** selon le protocole de traitement des données\"),\n    locations = cells_body(\n      columns = latest_date, rows = all()\n    )\n  )\n\ngt_summary\n\n\n\n\n\n\nInformations relatives aux fichiers de données\n\n\n(Valeurs théoriques)\n\n\nfile_extension\nfile_type\nlatest_date\nfile_count\n\n\n\n\n.nc\nFinalisé\n\n1 2024-12-05\n\n2 15802\n\n\n_preliminary.nc\nTemporaire\n\n1 2024-12-19\n\n2 15816\n\n\n\n\n\n1 Dates estimées selon le protocole de traitement des données\n\n\n\n2 Première collecte quotidienne datée du 01/09/1981",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Données SST</span>"
    ]
  },
  {
    "objectID": "SST_001_recuperation_donnees.html#remplissage-de-la-table-des-fichiers-de-données",
    "href": "SST_001_recuperation_donnees.html#remplissage-de-la-table-des-fichiers-de-données",
    "title": "\n2  Récupération des données SST\n",
    "section": "\n2.3 Remplissage de la table des fichiers de données",
    "text": "2.3 Remplissage de la table des fichiers de données\nCréation d’un tibble tib_sst composée des colonnes suivantes :\n\ndate : date de récupération des données\ndata_filename : nom local du fichier de données\ndata_url : url permettant d’accéder aux données pour une date donnée\n\n\n\n\n\n\n\nNote\n\n\n\nLa problématique consiste à mettre à jour au fil de l’eau les données qui sont initialement enregistrées dans un fichier avec l’extension **preliminary.nc” le temps que les données soient “validées”. Cette opération se déroule sur un délai d’approximativement 2 semaines à partir de la récupération des données.\n\n\nLe fichier tib_expected contient les informations relatives à l’ensemble des données théoriquement entreposées sur le serveur.\n\nCode# remplissage du champ date\n\ntib_expected &lt;- tibble(\n  date = seq(ymd(\"1981-09-01\"), latest_preliminary_date, by = \"days\")\n)\n\n# remplissage du champ data_url\n\nurl_finalized_data &lt;- get_all_url(\n  start_date = ymd(\"1981-09-01\"),\n  end_date = latest_finalized_date,\n  is.preliminary = FALSE\n)\n  \nurl_preliminary_data &lt;- get_all_url(\n  start_date = latest_finalized_date + 1,\n  end_date = latest_preliminary_date,\n  is.preliminary = TRUE\n)\n\ntib_expected$data_url &lt;- c(url_finalized_data, url_preliminary_data)\n\n# remplissage du champ data_filename\n\ntib_expected$data_filename &lt;- tib_expected$data_url |&gt;\n  map(\\(x) {tail(stri_split_fixed(x, \"/\")[[1]], n = 1)}) |&gt; \n  unlist()\n\n\nLe champ data_files_loaded de type logique permet de connaître la liste des fichiers de données déjà présents dans le dossier DATA/RAW\n\n# data_loaded renseigne sur la présence du fichier en local (dossier DATA/RAW)\n\ndata_files &lt;- tib_expected$data_filename\ndata_files_loaded &lt;- list.files(path = \"DATA/RAW\", pattern = \"*.nc*\")\ndata_preliminary_loaded &lt;- list.files(\n  path = \"DATA/RAW\", pattern = \"*_preliminary.nc*\"\n)\ntib_expected$data_loaded &lt;- (data_files %in% data_files_loaded)\n\n\ndata_files_to_delete &lt;- data_files_loaded[!(data_files_loaded %in% data_files)]\nif (length(data_files_to_delete &gt; 0)) {\n  unlink(paste(\"DATA/RAW\", data_files_to_delete, sep = \"/\"))\n}",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Données SST</span>"
    ]
  },
  {
    "objectID": "SST_001_recuperation_donnees.html#téléchargement-des-données-sst-si-nécessaire-avec-data_loaded-false",
    "href": "SST_001_recuperation_donnees.html#téléchargement-des-données-sst-si-nécessaire-avec-data_loaded-false",
    "title": "\n2  Récupération des données SST\n",
    "section": "\n2.4 Téléchargement des données SST (si nécessaire avec data_loaded == FALSE)",
    "text": "2.4 Téléchargement des données SST (si nécessaire avec data_loaded == FALSE)\n\nget_unloaded_data &lt;- function(data_filename, data_url) {\n  \n  file_path &lt;- paste(\"DATA/RAW\" , data_filename, sep = \"/\")\n  status_code &lt;- status_code(GET(data_url))\n  message(status_code)\n  if (status_code == 200) {\n    res &lt;- httr::GET(data_url,\n                     write_disk(file_path, overwrite = TRUE),\n                     progress()\n                    )\n  } else {\n    message(glue(\"The data for file {data_filename} are inaccessible\"))\n  }\n  \n}\n\ndata_files_unloaded &lt;- tib_expected |&gt; \n  dplyr::filter(!data_loaded)\ndata_filenames &lt;- data_files_unloaded$data_filename\ndata_urls &lt;- data_files_unloaded$data_url\npwalk(list(data_filenames, data_urls), get_unloaded_data)\n\n\n# data_loaded renseigne sur la présence du fichier en local (dossier DATA)\n\ntib_sst &lt;- tib_expected\ndata_files &lt;- tib_sst$data_filename\ndata_files_loaded &lt;- list.files(path = \"DATA/RAW\", pattern = \"*.nc*\")\ntib_sst$data_loaded &lt;- (data_files %in% data_files_loaded)\n\nsaveRDS(tib_sst, \"DATA/tib_sst.RDS\")",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Données SST</span>"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "1.1 Présentation des données exploitées\nLe NOAA1 présente au travail du portail du NCEI2 un ensemble de données environnementales.\nNous allons ici considérer les relevés quotidiens de la température de surface de l’eau de mer au niveau mondial.\nLes données brutes recensées par différentes sondes (satellites, navires, bouées) sur un maillage régulier de 0,25° par 0,25° sont combinées et les lacunes sont comblées par interpolation.\nCes données traitées sont ensuite mises à disposition sur le site de la NOAA sour forme de fichiers NetCDF.\nElles sont accessibles ici sous la rubrique sea-surface-temperature-optimum-interpolation\nDes informations complémentaires sur cet ensemble de données sont disponibles ici.\nNous allons tenter de générer le même type de graphes temporels que ceux disponibles sur le site de Climate Reanalyzer et accessibles sur la page Daily Sea Surface Temperature.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "intro.html#footnotes",
    "href": "intro.html#footnotes",
    "title": "1  Introduction",
    "section": "",
    "text": "National Oceanic and Atmospheric Administration↩︎\nNational Centers for Environmental Information↩︎",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "SST_02_timeseries.html",
    "href": "SST_02_timeseries.html",
    "title": "\n4  Données temporelles\n",
    "section": "",
    "text": "4.1 chargement librairies utiles\nlibs &lt;- c(\n  \"ncdf4\",\n  \"tidyverse\",\n  \"data.table\",\n  \"jsonlite\",\n  \"tictoc\",\n  \"fpp3\",\n  \"stringi\"\n)\n#install missing libraries\ninstalled_libs &lt;- libs %in% rownames(installed.packages())\nif (any(installed_libs == FALSE)) {\n  install.packages(libs[!installed_libs])\n}\n#load libraries\ninvisible(lapply(libs, library, character.only = TRUE))",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Données temporelles</span>"
    ]
  },
  {
    "objectID": "SST_02_timeseries.html#fonctions-de-base-peut-être-disponibles-dans-lubridate",
    "href": "SST_02_timeseries.html#fonctions-de-base-peut-être-disponibles-dans-lubridate",
    "title": "\n4  Données temporelles\n",
    "section": "\n4.2 fonctions de base (peut-être disponibles dans lubridate)",
    "text": "4.2 fonctions de base (peut-être disponibles dans lubridate)\n\nyyyymm &lt;- function(date) {\n  return(gsub(\"-\", \"\", stri_sub(date, 1, 7)))\n}\n\nyyyymmdd &lt;- function(date) { \n  return(gsub(\"-\", \"\", date))\n}",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Données temporelles</span>"
    ]
  },
  {
    "objectID": "SST_02_timeseries.html#weights-to-apply-to-square-of-0.25x0.25-along-the-latitude",
    "href": "SST_02_timeseries.html#weights-to-apply-to-square-of-0.25x0.25-along-the-latitude",
    "title": "\n4  Données temporelles\n",
    "section": "\n4.3 weights to apply to square of 0.25°x0.25° along the latitude",
    "text": "4.3 weights to apply to square of 0.25°x0.25° along the latitude\n\narea_weights &lt;- fread(\n  file = \"DATA/area_weights.csv\",\n  dec = \",\"\n) |&gt; pull( w )\n# matrix_area_weights &lt;- matrix(rep(area_weights, 1440), nrow = 1440, byrow = TRUE)\n# wmean &lt;- weighted.mean(sst, matrix_area_weights, na.rm = TRUE)\n# wmean_60_60 &lt;- weighted.mean(sst[,121:600], matrix_area_weights[,121:600], na.rm = TRUE)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Données temporelles</span>"
    ]
  },
  {
    "objectID": "SST_02_timeseries.html#fonctions-de-calcul-de-moyenne-pondérée",
    "href": "SST_02_timeseries.html#fonctions-de-calcul-de-moyenne-pondérée",
    "title": "\n4  Données temporelles\n",
    "section": "\n4.4 fonctions de calcul de moyenne pondérée",
    "text": "4.4 fonctions de calcul de moyenne pondérée\nLe principe consiste à détecter un fichier de moyenne (fichier RDS) déjà présent ou pas.\nSi ce dernier est présent il est lu et complété.\nDans le cas contraire la constition de ce fichier est réalisée à partir de tous les fichiers NetCDF contenus dans le répertoire DATA/RAW.\nSi le fichier pris en compte est un fichier temporaire (suffixe _preliminary) on attribuera à la donnée un status_ok de valeur \\(FALSE\\)\nSi le fichier pris en compte est un fichier finalisé status_okvaudra \\(TRUE\\)\n\n# get weighted mean of one variable between longitude and latitude ranges\n\nget_weighted_mean &lt;- function(file, var, lon_min, lon_max, lat_min, lat_max) {\n\n  status_ok &lt;- if_else(str_detect(file, '_preliminary'), FALSE, TRUE)\n  nc &lt;- nc_open(file)\n  lon &lt;- ncvar_get(nc, varid = \"lon\")\n  lat &lt;- ncvar_get(nc, varid = \"lat\")\n  time &lt;- ncvar_get(nc, varid = \"time\")\n  var &lt;- ncvar_get(nc, varid = var)\n  nc_close(nc)\n\n  w &lt;- matrix(rep(area_weights, 1440), ncol = 720, byrow = TRUE)\n  x_min &lt;- min(which(lon &gt;= lon_min))\n  x_max &lt;- max(which(lon &lt;= lon_max))\n  y_min &lt;- min(which(lat &gt;= lat_min))\n  y_max &lt;- max(which(lat &lt;= lat_max))\n  \n  wm_var &lt;- weighted.mean(\n    var[x_min:x_max, y_min:y_max], \n    w[x_min:x_max, y_min:y_max], \n    na.rm = TRUE\n  )\n  c(time, wm_var, status_ok)\n\n}\n\n\n# var : 'sst', 'anom' or 'ice \n# geo_data : list (RDS_name, bbox)\n\nget_all_weighted_mean &lt;- function(var, geo_data) {\n\n  files &lt;- list.files(path = \"DATA/RAW\", pattern = \"*.nc\", full.names = TRUE)\n  if (length(files) &gt; 0 ) {\n    lon_min &lt;- geo_data$bbox[\"lon_min\"]\n    lon_max &lt;- geo_data$bbox[\"lon_max\"]\n    lat_min &lt;- geo_data$bbox[\"lat_min\"]\n    lat_max &lt;- geo_data$bbox[\"lat_max\"]\n    RDS_file &lt;- paste0('wm_', var, '_', geo_data$RDS_name, '.RDS')\n    RDS_file_path &lt;- paste(\"DATA\", RDS_file, sep = '/')\n    if (file.exists(RDS_file_path)) {\n      # les données relatives aux fichiers _preliminary sont supprimées\n      RDS_data &lt;- readRDS(RDS_file_path) |&gt; \n        dplyr::filter(status_ok)\n      saveRDS(RDS_data, RDS_file_path) \n      finalized_files_processed &lt;- RDS_data |&gt;\n        pull(date) |&gt; \n        yyyymmdd() |&gt; \n        vapply(\\(x) paste0('DATA/RAW/oisst-avhrr-v02r01.', x, '.nc'), character(1))\n      files_to_process &lt;- files[!(files %in% finalized_files_processed)]\n    } else {\n      files_to_process &lt;- files\n    }\n    origin_date &lt;- ymd(\"1978-01-01\")\n    wm_matrix &lt;- matrix(numeric(0), nrow = length(files_to_process), ncol = 3)\n    colnames(wm_matrix) &lt;- c('time', 'wm', 'status_ok')\n    for (i in seq_along(files_to_process)) { \n      result &lt;- get_weighted_mean(files_to_process[i], var, lon_min, lon_max, lat_min, lat_max)\n      wm_matrix[i, 1] &lt;- result[1] # time in days from origin date\n      wm_matrix[i, 2] &lt;- result[2] # weighted mean\n      wm_matrix[i, 3] &lt;- result[3] # status\n    }\n    df_wm_var &lt;- as_tibble(wm_matrix) |&gt;\n      set_names('time', paste0('wm_', var), 'status_ok') |&gt; \n      mutate(\n        date = lubridate::as_date(time, origin = origin_date),\n        status_ok = as.logical(status_ok)\n      )\n    if (file.exists(RDS_file_path)) {\n      RDS_data &lt;- rbind(RDS_data, df_wm_var)\n    } else {\n      RDS_data &lt;- df_wm_var\n    }\n    saveRDS(RDS_data, RDS_file_path)\n    RDS_data\n  } else { \n    message(\"aucun fichier de données à traiter\") \n  }\n  \n}",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Données temporelles</span>"
    ]
  },
  {
    "objectID": "SST_02_timeseries.html#calcul-des-moyennes-pondérées-pour-le-monde-60s-60n",
    "href": "SST_02_timeseries.html#calcul-des-moyennes-pondérées-pour-le-monde-60s-60n",
    "title": "\n4  Données temporelles\n",
    "section": "\n4.5 calcul des moyennes pondérées pour le monde (60°S-60°N)",
    "text": "4.5 calcul des moyennes pondérées pour le monde (60°S-60°N)\nLes moyennes pondérées sont calculées consécutivement sur les variables sst, anom, et ice.\n\n# get weighted mean var with -60 &lt; latitude &lt; 60\n\ngeo_world &lt;- list(\n  RDS_name = \"world\", \n  bbox = c(lon_min = 0, lon_max = 360, lat_min = -60, lat_max = 60)\n)\n\ndf_wm_sst_world &lt;- get_all_weighted_mean(\"sst\", geo_world)\ndf_wm_anom_world &lt;- get_all_weighted_mean(\"anom\", geo_world)\ndf_wm_ice_world &lt;- get_all_weighted_mean(\"ice\", geo_world)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Données temporelles</span>"
    ]
  },
  {
    "objectID": "SST_02_timeseries.html#calcul-des-moyennes-pondérées-pour-latlantique-nord-0-60n-0-80w",
    "href": "SST_02_timeseries.html#calcul-des-moyennes-pondérées-pour-latlantique-nord-0-60n-0-80w",
    "title": "\n4  Données temporelles\n",
    "section": "\n4.6 calcul des moyennes pondérées pour l’Atlantique Nord (0-60°N, 0-80W)",
    "text": "4.6 calcul des moyennes pondérées pour l’Atlantique Nord (0-60°N, 0-80W)\nLes mêmes variables que précédemment sont prises en compte.\n\ngeo_north_atlantic &lt;- list(\n  RDS_name = \"north_atlantic\",\n  bbox = c(lon_min = 280, lon_max = 360, lat_min = 0, lat_max = 60)\n)\n\ndf_wm_sst_north_atlantic &lt;- get_all_weighted_mean(\"sst\", geo_north_atlantic)\ndf_wm_anom_north_atlantic &lt;- get_all_weighted_mean(\"anom\", geo_north_atlantic)\ndf_wm_ice_north_atlantic &lt;- get_all_weighted_mean(\"ice\", geo_north_atlantic)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Données temporelles</span>"
    ]
  },
  {
    "objectID": "SST_02_timeseries.html#impression-de-la-série-temporelle",
    "href": "SST_02_timeseries.html#impression-de-la-série-temporelle",
    "title": "\n4  Données temporelles\n",
    "section": "\n4.7 Impression de la série temporelle",
    "text": "4.7 Impression de la série temporelle\n\ndf_wm_sst &lt;- readRDS('DATA/wm_sst_world.RDS') |&gt; \n  mutate(\n    year = year(date),\n    yday = yday(date),\n    month = month(date)\n    ) \n\nggplot(data = df_wm_sst,\n       aes(x = yday, y = wm_sst, group = year)) +\n  geom_line(aes(color = factor(year))) +\n  scale_color_grey(start = 0.8, end = 0.2) +\n  geom_line(\n    data = df_wm_sst |&gt; filter(year == 2023),\n    aes(x = yday, y = wm_sst),\n    color = \"orange\",\n    linewidth = 1) +\n  geom_line(\n    data = df_wm_sst |&gt; filter(year == 2024),\n    aes(x = yday, y = wm_sst, group = year),\n    color = \"black\", \n    linewidth = 1) +\n  labs(\n    title = \"Daily Sea Surface Temperature, World (60°S-60°N, 0-360°E)\",\n    subtitle = \"Dataset: NOAA OISST V2.1\",\n    caption = 'caption test',\n    color = NULL,\n    x = NULL,\n    y = NULL\n  ) -&gt; p\n\np + \n  theme_bw() +\n  theme(\n    legend.position = \"bottom\",\n    plot.caption = element_text(margin = margin(t = 0, unit = 'cm')),\n    legend.spacing.x = unit(0.5, 'cm'),\n    legend.key = element_blank(),\n    legend.text = element_text(colour = 'black'),\n  ) +\n  guides(\n    color = guide_legend(\n      ncol = 7, \n      byrow = TRUE, \n      reverse = FALSE,\n      label = TRUE,\n      #label.hjust = 1,\n      #keywidth = unit(0.8, 'cm'),\n      label.position = \"right\",\n      x.intersp = 0.2,\n      text.width = 0.045\n    )\n  )",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Données temporelles</span>"
    ]
  },
  {
    "objectID": "SST_02_timeseries.html#impression-supplémentaire-1",
    "href": "SST_02_timeseries.html#impression-supplémentaire-1",
    "title": "\n4  Données temporelles\n",
    "section": "\n4.8 impression supplémentaire 1",
    "text": "4.8 impression supplémentaire 1\n\nggplot(data = df_wm_sst,\n       aes(x = date, y = wm_sst)) +\n  geom_line() +\n  geom_smooth(\n    method = \"lm\",\n    se = FALSE\n  ) + \n  geom_smooth(\n    data = df_wm_sst |&gt; \n      filter(year &gt; 2000),\n    method = \"lm\",\n    se = FALSE, colour = \"#FFA050\"\n  ) +\n  geom_smooth(\n    data = df_wm_sst |&gt; \n      filter(year &gt; 2010),\n    method = \"lm\",\n    se = FALSE, colour = \"#FF0000\"\n  )\n\n`geom_smooth()` using formula = 'y ~ x'\n`geom_smooth()` using formula = 'y ~ x'\n`geom_smooth()` using formula = 'y ~ x'",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Données temporelles</span>"
    ]
  },
  {
    "objectID": "SST_02_timeseries.html#impression-supplémentaire-2",
    "href": "SST_02_timeseries.html#impression-supplémentaire-2",
    "title": "\n4  Données temporelles\n",
    "section": "\n4.9 impression supplémentaire 2",
    "text": "4.9 impression supplémentaire 2\n\ndf_wm_sst &lt;- readRDS(\"DATA/wm_sst_world.RDS\") |&gt; \n  mutate(year = year(date))\nggplot(data = df_wm_sst) +\n  geom_line(aes(x = date, y = wm_sst, group = year, color = year))",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Données temporelles</span>"
    ]
  },
  {
    "objectID": "SST_03_levelplot.html",
    "href": "SST_03_levelplot.html",
    "title": "\n4  Données SST du 21 novembre 2024\n",
    "section": "",
    "text": "4.1 Exploration du fichier NetCDF (comme décrit ici)\nlibs &lt;- c(\n  \"ncdf4\",\n  \"tidyverse\",\n  \"terra\",\n  \"sf\"\n)\n\n#install missing libraries\ninstalled_libs &lt;- libs %in% rownames(installed.packages())\nif (any(installed_libs == FALSE)) {\n  install.packages(libs[!installed_libs])\n}\n\n#load libraries\ninvisible(lapply(libs, library, character.only = TRUE))\nLa connexion au fichier NetCDF s’opère via la commande nc_open.\nGrâce à elle nous pouvons déjà voir quel type d’informations sont enregistrées.\n(nc &lt;- nc_open(\"DATA/RAW/oisst-avhrr-v02r01.20241201.nc\"))\n\nFile DATA/RAW/oisst-avhrr-v02r01.20241201.nc (NC_FORMAT_NETCDF4):\n\n     4 variables (excluding dimension variables):\n        short sst[lon,lat,zlev,time]   (Chunking: [1440,720,1,1])  (Compression: shuffle,level 4)\n            long_name: Daily sea surface temperature\n            units: Celsius\n            _FillValue: -999\n            add_offset: 0\n            scale_factor: 0.00999999977648258\n            valid_min: -300\n            valid_max: 4500\n        short anom[lon,lat,zlev,time]   (Chunking: [1440,720,1,1])  (Compression: shuffle,level 4)\n            long_name: Daily sea surface temperature anomalies\n            units: Celsius\n            _FillValue: -999\n            add_offset: 0\n            scale_factor: 0.00999999977648258\n            valid_min: -1200\n            valid_max: 1200\n        short err[lon,lat,zlev,time]   (Chunking: [1440,720,1,1])  (Compression: shuffle,level 4)\n            long_name: Estimated error standard deviation of analysed_sst\n            units: Celsius\n            _FillValue: -999\n            add_offset: 0\n            scale_factor: 0.00999999977648258\n            valid_min: 0\n            valid_max: 1000\n        short ice[lon,lat,zlev,time]   (Chunking: [1440,720,1,1])  (Compression: shuffle,level 4)\n            long_name: Sea ice concentration\n            units: %\n            _FillValue: -999\n            add_offset: 0\n            scale_factor: 0.00999999977648258\n            valid_min: 0\n            valid_max: 100\n\n     4 dimensions:\n        time  Size:1   *** is unlimited *** \n            long_name: Center time of the day\n            units: days since 1978-01-01 12:00:00\n        zlev  Size:1 \n            long_name: Sea surface height\n            units: meters\n            positive: down\n            actual_range: 0, 0\n        lat  Size:720 \n            long_name: Latitude\n            units: degrees_north\n            grids: Uniform grid from -89.875 to 89.875 by 0.25\n        lon  Size:1440 \n            long_name: Longitude\n            units: degrees_east\n            grids: Uniform grid from 0.125 to 359.875 by 0.25\n\n    37 global attributes:\n        Conventions: CF-1.6, ACDD-1.3\n        title: NOAA/NCEI 1/4 Degree Daily Optimum Interpolation Sea Surface Temperature (OISST) Analysis, Version 2.1 - Final\n        references: Reynolds, et al.(2007) Daily High-Resolution-Blended Analyses for Sea Surface Temperature (available at https://doi.org/10.1175/2007JCLI1824.1). Banzon, et al.(2016) A long-term record of blended satellite and in situ sea-surface temperature for climate monitoring, modeling and environmental studies (available at https://doi.org/10.5194/essd-8-165-2016). Huang et al. (2020) Improvements of the Daily Optimum Interpolation Sea Surface Temperature (DOISST) Version v02r01, submitted.Climatology is based on 1971-2000 OI.v2 SST. Satellite data: Pathfinder AVHRR SST, Navy AVHRR SST, and NOAA ACSPO SST. Ice data: NCEP Ice and GSFC Ice.\n        source: ICOADS, NCEP_GTS, GSFC_ICE, NCEP_ICE, Pathfinder_AVHRR, Navy_AVHRR, NOAA_ACSP\n        id: oisst-avhrr-v02r01.20241201.nc\n        naming_authority: gov.noaa.ncei\n        summary: NOAAs 1/4-degree Daily Optimum Interpolation Sea Surface Temperature (OISST) (sometimes referred to as Reynolds SST, which however also refers to earlier products at different resolution), currently available as version v02r01, is created by interpolating and extrapolating SST observations from different sources, resulting in a smoothed complete field. The sources of data are satellite (AVHRR) and in situ platforms (i.e., ships and buoys), and the specific datasets employed may change over time. At the marginal ice zone, sea ice concentrations are used to generate proxy SSTs.  A preliminary version of this file is produced in near-real time (1-day latency), and then replaced with a final version after 2 weeks. Note that this is the AVHRR-ONLY DOISST, available from Oct 1981, but there is a companion DOISST product that includes microwave satellite data, available from June 2002\n        cdm_data_type: Grid\n        history: Final file created using preliminary as first guess, and 3 days of AVHRR data. Preliminary uses only 1 day of AVHRR data.\n        date_modified: 2024-12-16T14:43:00Z\n        date_created: 2024-12-16T14:43:00Z\n        product_version: Version v02r01\n        processing_level: NOAA Level 4\n        institution: NOAA/National Centers for Environmental Information\n        creator_url: https://www.ncei.noaa.gov/\n        creator_email: oisst-help@noaa.gov\n        keywords: Earth Science &gt; Oceans &gt; Ocean Temperature &gt; Sea Surface Temperature\n        keywords_vocabulary: Global Change Master Directory (GCMD) Earth Science Keywords\n        platform: Ships, buoys, Argo floats, MetOp-A, MetOp-B\n        platform_vocabulary: Global Change Master Directory (GCMD) Platform Keywords\n        instrument: Earth Remote Sensing Instruments &gt; Passive Remote Sensing &gt; Spectrometers/Radiometers &gt; Imaging Spectrometers/Radiometers &gt; AVHRR &gt; Advanced Very High Resolution Radiometer\n        instrument_vocabulary: Global Change Master Directory (GCMD) Instrument Keywords\n        standard_name_vocabulary: CF Standard Name Table (v40, 25 January 2017)\n        geospatial_lat_min: -90\n        geospatial_lat_max: 90\n        geospatial_lon_min: 0\n        geospatial_lon_max: 360\n        geospatial_lat_units: degrees_north\n        geospatial_lat_resolution: 0.25\n        geospatial_lon_units: degrees_east\n        geospatial_lon_resolution: 0.25\n        time_coverage_start: 2024-12-01T00:00:00Z\n        time_coverage_end: 2024-12-01T23:59:59Z\n        metadata_link: https://doi.org/10.25921/RE9P-PT57\n        ncei_template_version: NCEI_NetCDF_Grid_Template_v2.0\n        comment: Data was converted from NetCDF-3 to NetCDF-4 format with metadata updates in November 2017.\n        sensor: Thermometer, AVHRR",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Un fichier SST</span>"
    ]
  },
  {
    "objectID": "SST_03_levelplot.html#exploration-du-fichier-netcdf-comme-décrit-ici",
    "href": "SST_03_levelplot.html#exploration-du-fichier-netcdf-comme-décrit-ici",
    "title": "\n4  Données SST du 21 novembre 2024\n",
    "section": "",
    "text": "4.1.1 Les dimensions\nles variables principales sont discriminées suivant plusieurs dimensions.\nIci, ce sont :\n\nlon : la longitude (de taille \\(1440=\\frac{360}{0.25}\\))\nlat : la latitude (de taille \\(720=\\frac{180}{0.25}\\))\nzlev : La hauteur de la surface de l’eau de mer\ntime : temps central de la journée\n\n\n\n\n\n\n\nNote\n\n\n\n\n\n\nLes longitudes sont ordonnées de l’Est vers l’Ouest en partant du méridien de Greenwich depuis la valeur \\(0.125\\) jusqu’à la valeur \\(0.125+1439*0.25=359.875\\)\nLes latitudes sont ordonnées du Sud au Nord dans l’array lat en partant du pôle Sud depuis la valeur \\(-90+0.125=-89.875\\) jusqu’à la valeur \\(-89.875+719*0.25=89.875\\)\n\n\n\n\nIl est possible d’avoir accès aux données des dimensions via la fonction ncvar_get et l’accès aux attributs avec la fonction ncatt_get\n\n# get info about latitudes\nlat &lt;- ncvar_get(nc, \"lat\")\n(lat_units &lt;- ncatt_get(nc, \"lat\", \"units\"))\n\n$hasatt\n[1] TRUE\n\n$value\n[1] \"degrees_north\"\n\n# get info about longitudes\nlon &lt;- ncvar_get(nc, \"lon\")\n(lon_units &lt;- ncatt_get(nc, \"lon\", \"units\"))\n\n$hasatt\n[1] TRUE\n\n$value\n[1] \"degrees_east\"\n\n# get info about time\ntime &lt;- ncvar_get(nc, \"time\")\n(time_units &lt;- ncatt_get(nc, \"time\", \"units\"))\n\n$hasatt\n[1] TRUE\n\n$value\n[1] \"days since 1978-01-01 12:00:00\"\n\ntime_as_date &lt;- as.Date(time, origin = \"1978-01-01 12:00:0\", tz = \"UTC\")\n# get info about zlev\nzlev &lt;- ncvar_get(nc, \"zlev\")\n(zlev_units &lt;- ncatt_get(nc, \"zlev\", \"units\"))\n\n$hasatt\n[1] TRUE\n\n$value\n[1] \"meters\"\n\n\n\n4.1.2 Les variables principales\nNous avons quatre variables stockées dans le fichier :\n\nsst : la température quotidienne de la surface de l’eau\nanom : les anomalies quotidiennes de température de surface de l’eau\nerr : estimated error standard deviation of analysed_sst\nice : la concentration en glace\n\n\n(nc_var &lt;- names(nc$var))\n\n[1] \"sst\"  \"anom\" \"err\"  \"ice\" \n\n# get info about variable attribute\nget_var_attribute &lt;- function(var, attribute) {\n  nc_var &lt;- names(nc$var)\n  if (!(var %in% nc_var)) {\n    message(paste(\"la variable\", var, \"est inexistante\"))\n  } else {\n  ln &lt;- ncatt_get(nc, var, attname = attribute)\n  ifelse(ln$hasatt, ln$value, paste(\"pas d'attribut \", attribute))\n  }\n}\n\n# long names\nget_var_long_name &lt;- function() {\n  vapply(\n  nc_var, \n  get_var_attribute, \n  FUN.VALUE = character(1), \n  \"long_name\"\n  )\n}\n((get_var_long_name()))\n\n                                                 sst \n                     \"Daily sea surface temperature\" \n                                                anom \n           \"Daily sea surface temperature anomalies\" \n                                                 err \n\"Estimated error standard deviation of analysed_sst\" \n                                                 ice \n                             \"Sea ice concentration\" \n\n# source\nget_var_units &lt;- function() {\n  vapply(\n  nc_var, \n  get_var_attribute, \n  FUN.VALUE = character(1), \n  \"units\"\n  )\n}\n((get_var_units()))\n\n      sst      anom       err       ice \n\"Celsius\" \"Celsius\" \"Celsius\"       \"%\" \n\n# fill value\nget_var_fill_value &lt;- function() {\n  vapply(\n  nc_var, \n  get_var_attribute, \n  FUN.VALUE = numeric(1), \n  \"_FillValue\"\n  )\n}\n((get_var_fill_value()))\n\n sst anom  err  ice \n-999 -999 -999 -999 \n\n\n\n4.1.3 Les attributs globaux du fichier\n\natt &lt;- c(\"title\", \"institution\", \"source\", \"references\", \"history\", \"Conventions\") \nget_global_attribute &lt;- function(att) {\n  ncatt_get(nc, 0, att)$value\n}\n(global_attributes &lt;- vapply(att, get_global_attribute, FUN.VALUE = character(1)))\n\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        title \n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \"NOAA/NCEI 1/4 Degree Daily Optimum Interpolation Sea Surface Temperature (OISST) Analysis, Version 2.1 - Final\" \n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  institution \n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \"NOAA/National Centers for Environmental Information\" \n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       source \n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \"ICOADS, NCEP_GTS, GSFC_ICE, NCEP_ICE, Pathfinder_AVHRR, Navy_AVHRR, NOAA_ACSP\" \n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   references \n\"Reynolds, et al.(2007) Daily High-Resolution-Blended Analyses for Sea Surface Temperature (available at https://doi.org/10.1175/2007JCLI1824.1). Banzon, et al.(2016) A long-term record of blended satellite and in situ sea-surface temperature for climate monitoring, modeling and environmental studies (available at https://doi.org/10.5194/essd-8-165-2016). Huang et al. (2020) Improvements of the Daily Optimum Interpolation Sea Surface Temperature (DOISST) Version v02r01, submitted.Climatology is based on 1971-2000 OI.v2 SST. Satellite data: Pathfinder AVHRR SST, Navy AVHRR SST, and NOAA ACSPO SST. Ice data: NCEP Ice and GSFC Ice.\" \n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      history \n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \"Final file created using preliminary as first guess, and 3 days of AVHRR data. Preliminary uses only 1 day of AVHRR data.\" \n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Conventions \n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \"CF-1.6, ACDD-1.3\"",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Un fichier SST</span>"
    ]
  },
  {
    "objectID": "SST_03_levelplot.html#exploration-des-variables",
    "href": "SST_03_levelplot.html#exploration-des-variables",
    "title": "\n4  Données SST du 21 novembre 2024\n",
    "section": "\n4.2 Exploration des variables",
    "text": "4.2 Exploration des variables\n\nnc_var &lt;- names(nc$var)\n\nnc_charge_var &lt;- function(var) {\n  nc_var &lt;- ncvar_get(nc = nc, varid = var )\n  envir &lt;- globalenv()\n  assign(var, nc_var, envir = envir)\n}\n\nwalk(nc_var, nc_charge_var)\n\nLa variable sst est enregistrée en tant que matrix, array avec les dimensions 1440, 720\n\nLa longitude correspond à la 1ère dimension (lignes de la matrice)\nLa latitude correspond à la 2ème dimension (colonnes de la matrice)\nLe vecteur associé est obtenu en parcourant d’abord les 1440 longitudes d’un parallèle avant de passer à la latitude suivante.\n\n\nlonlat &lt;- expand.grid(lon, lat)\ndf_sst &lt;- cbind(lonlat, as.vector(sst))\nnames(df_sst) &lt;- c(\"lon\", \"lat\", \"sst\")\nhead(df_sst)\n\n    lon     lat sst\n1 0.125 -89.875  NA\n2 0.375 -89.875  NA\n3 0.625 -89.875  NA\n4 0.875 -89.875  NA\n5 1.125 -89.875  NA\n6 1.375 -89.875  NA",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Un fichier SST</span>"
    ]
  },
  {
    "objectID": "SST_03_levelplot.html#affichage-de-la-carte-des-données-sst",
    "href": "SST_03_levelplot.html#affichage-de-la-carte-des-données-sst",
    "title": "\n4  Données SST du 21 novembre 2024\n",
    "section": "\n4.3 Affichage de la carte des données sst",
    "text": "4.3 Affichage de la carte des données sst\nAvec positionnement en rouge du point de test donné en exemple :\n\n#|label: plot_sst\n\ndf_sst |&gt; \n  ggplot(aes(x = lon, y = lat, color = sst)) + \n  geom_point(size = 0.5) +\n  coord_fixed(expand = FALSE) +\n  scale_colour_distiller(palette = \"RdBu\") +\n  labs(\n    x = NULL,\n    y = NULL,\n    title = \"Sea Surface Temperature\",\n    subtitle = time_as_date,\n    caption = \"Dataset: NOAA OISST V2.1\",\n    color = \"°C\"\n  )",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Un fichier SST</span>"
    ]
  },
  {
    "objectID": "SST_03_levelplot.html#calcul-de-moyenne-globale",
    "href": "SST_03_levelplot.html#calcul-de-moyenne-globale",
    "title": "\n4  Données SST du 21 novembre 2024\n",
    "section": "\n4.4 Calcul de moyenne globale",
    "text": "4.4 Calcul de moyenne globale\nIl semble qu’il faille appliquer un poids fonction de \\(\\alpha\\) en radians pour pondérer les mesures de surface en fonction de la latitude considérée.\nPour calculer ces poids j’ai construit tous les polygones “carrés” de 0.25° de côté suivant un même méridien.\nCes polygones ont pour centre les coordonnées (longitude et latitude) de la mesure SST correspondante.\nJ’ai ensuite calculé les aires de ces polygones avec le système de coordonnées de référence EPSG:4326 (WGS84).\nLes poids relatifs à chaque mesure ont été fixés comme étant les ratio des aires obtenues avec celle de la plus grande aire (aire du polygone situé à l’équateur).\n\n4.4.1 Calcul des poids à affecter aux mesures suivant la latitude associée\n\n# fonction génératrice de \"carré géographique\" de n degrés de côté\n# le point de base (lon, lat) est le point inférieur gauche. \n\npolygone_geo &lt;- function(lon, lat, n) {\n  polygon_list &lt;- list(rbind(\n    c(lon, lat),\n    c(lon + n, lat),\n    c(lon + n, lat + n),\n    c(lon, lat + n),\n    c(lon, lat)\n  ))\n  st_polygon(polygon_list)\n}\n\npolygone_sfc &lt;- seq(-90, 89.75, by = 0.25) |&gt;\n  map(\\(x) polygone_geo(lon = 0, lat = x, n = 0.25)) |&gt; \n  st_sfc(crs = \"EPSG:4326\")\n\narea_weights &lt;- as.numeric(st_area(polygone_sfc) / max(st_area(polygone_sfc)))\nhead(area_weights)\n\n[1] 0.002181655 0.006544922 0.010908066 0.015271001 0.019633646 0.023995917\n\n\n\ndf_area_weights &lt;- expand.grid(lon, area_weights)\nnames(df_area_weights) &lt;- c(\"lon\", \"w\")\nw &lt;- df_area_weights$w\ndf_sst_weights &lt;- cbind(df_sst, w)\n\n# moyenne pondérée globale\nsst_weighted_mean &lt;- df_sst_weights |&gt; \n  summarize(wm_sst = weighted.mean(sst, w, na.rm = TRUE))\nsst_weighted_mean\n\n    wm_sst\n1 18.44787\n\n# moyenne pondérée entre -60°S et +60°N\ndf_sst_60S_60N &lt;- df_sst_weights |&gt; \n  filter(lat &gt;= -60 & lat &lt;= 60)\nsst_weighted_mean_60S_60N &lt;- df_sst_60S_60N |&gt; \n  summarize(wm_sst_60S_60N = weighted.mean(sst, w, na.rm = TRUE))\nsst_weighted_mean_60S_60N\n\n  wm_sst_60S_60N\n1       20.65579\n\n\nSi nous souhaitons centrer la carte sur le méridien de Greenwich, il est nécessaire de translater les longitudes.\n\n#|label: plot_sst_greenwich\n\ndf_sst |&gt; \n  mutate(lon = if_else(lon &gt; 180, lon - 360, lon)) |&gt; \n  ggplot(aes(x = lon, y = lat, fill = sst)) + \n  geom_raster() +\n  scale_fill_gradient2(\n    low = \"darkblue\",\n    mid = \"white\",\n    high = \"darkred\",\n    midpoint = 15\n  ) +\n  coord_fixed(expand = FALSE) +\n  #scale_colour_distiller(palette = \"RdBu\") +\n  labs(\n    x = NULL,\n    y = NULL,\n    title = \"Sea Surface Temperature\",\n    subtitle = paste0(\n      time_as_date,\n      \" - mean global = \",\n      round(sst_weighted_mean, 2),\n      \" °Celsius\",\n      \" | \",\n      \" mean World(60°S-60°N) = \",\n      round(sst_weighted_mean_60S_60N, 2),\n      \" °Celsius\"\n    ),\n    caption = \"Dataset: NOAA OISST V2.1\",\n    fill = \"°C\",\n  ) +\n  theme(\n    axis.text = element_blank(),\n    axis.ticks = element_blank(),\n    # panel.background = element_rect(fill = \"black\"),\n    # plot.background = element_rect(fill = \"black\")\n  )",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Un fichier SST</span>"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Fichiers NetCDF",
    "section": "",
    "text": "Preface",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "SST_001_recuperation_donnees.html#comptabilisation-des-fichiers-de-données-théoriquement-disponibles",
    "href": "SST_001_recuperation_donnees.html#comptabilisation-des-fichiers-de-données-théoriquement-disponibles",
    "title": "\n2  Récupération des données SST\n",
    "section": "\n2.3 Comptabilisation des fichiers de données théoriquement disponibles",
    "text": "2.3 Comptabilisation des fichiers de données théoriquement disponibles\n\n2.3.1 Comptabilisation théorique dans le tibble tib_expected\n\nLe tibble tib_expected contient les informations relatives à l’ensemble des données théoriquement entreposées sur le serveur (basées sur le protocole de production et de nommage des données)\n\ndate : date de production du fichier (temporaire ou finalisé)\n\ndata_url : url du fichier de données\ndata_filename : nom du fichier de données\n\nIl contient en plus une information permettant de savoir si le fichier a dèjà été téléchargé.\n\ndata_loaded : champ de type logique indiquant la présence des données du fichier en local dans le dossier DATA/RAW\n\n\n\nCodetib_expected &lt;- tibble(\n  date = seq(ymd(\"1981-09-01\"), latest_preliminary_date, by = \"days\")\n)\n\nurl_finalized_data &lt;- get_all_url(\n  start_date = ymd(\"1981-09-01\"),\n  end_date = latest_finalized_date,\n  is.preliminary = FALSE\n)\n  \nurl_preliminary_data &lt;- get_all_url(\n  start_date = latest_finalized_date + 1,\n  end_date = latest_preliminary_date,\n  is.preliminary = TRUE\n)\n\ntib_expected$data_url &lt;- c(url_finalized_data, url_preliminary_data)\n\ntib_expected$data_filename &lt;- tib_expected$data_url |&gt;\n  map(\\(x) {tail(stri_split_fixed(x, \"/\")[[1]], n = 1)}) |&gt; \n  unlist()\n\n\ndata_files &lt;- tib_expected$data_filename\ndata_files_loaded &lt;- list.files(path = \"DATA/RAW\", pattern = \"*.nc*\")\ndata_preliminary_loaded &lt;- list.files(\n  path = \"DATA/RAW\", pattern = \"*_preliminary.nc*\"\n)\ntib_expected$data_loaded &lt;- (data_files %in% data_files_loaded)\n\ntail(tib_expected, n = 20)\n\n# A tibble: 20 × 4\n   date       data_url                                 data_filename data_loaded\n   &lt;date&gt;     &lt;chr&gt;                                    &lt;chr&gt;         &lt;lgl&gt;      \n 1 2024-11-30 https://www.ncei.noaa.gov/data/sea-surf… oisst-avhrr-… TRUE       \n 2 2024-12-01 https://www.ncei.noaa.gov/data/sea-surf… oisst-avhrr-… TRUE       \n 3 2024-12-02 https://www.ncei.noaa.gov/data/sea-surf… oisst-avhrr-… TRUE       \n 4 2024-12-03 https://www.ncei.noaa.gov/data/sea-surf… oisst-avhrr-… TRUE       \n 5 2024-12-04 https://www.ncei.noaa.gov/data/sea-surf… oisst-avhrr-… TRUE       \n 6 2024-12-05 https://www.ncei.noaa.gov/data/sea-surf… oisst-avhrr-… TRUE       \n 7 2024-12-06 https://www.ncei.noaa.gov/data/sea-surf… oisst-avhrr-… TRUE       \n 8 2024-12-07 https://www.ncei.noaa.gov/data/sea-surf… oisst-avhrr-… TRUE       \n 9 2024-12-08 https://www.ncei.noaa.gov/data/sea-surf… oisst-avhrr-… TRUE       \n10 2024-12-09 https://www.ncei.noaa.gov/data/sea-surf… oisst-avhrr-… TRUE       \n11 2024-12-10 https://www.ncei.noaa.gov/data/sea-surf… oisst-avhrr-… TRUE       \n12 2024-12-11 https://www.ncei.noaa.gov/data/sea-surf… oisst-avhrr-… TRUE       \n13 2024-12-12 https://www.ncei.noaa.gov/data/sea-surf… oisst-avhrr-… TRUE       \n14 2024-12-13 https://www.ncei.noaa.gov/data/sea-surf… oisst-avhrr-… TRUE       \n15 2024-12-14 https://www.ncei.noaa.gov/data/sea-surf… oisst-avhrr-… TRUE       \n16 2024-12-15 https://www.ncei.noaa.gov/data/sea-surf… oisst-avhrr-… TRUE       \n17 2024-12-16 https://www.ncei.noaa.gov/data/sea-surf… oisst-avhrr-… TRUE       \n18 2024-12-17 https://www.ncei.noaa.gov/data/sea-surf… oisst-avhrr-… TRUE       \n19 2024-12-18 https://www.ncei.noaa.gov/data/sea-surf… oisst-avhrr-… TRUE       \n20 2024-12-19 https://www.ncei.noaa.gov/data/sea-surf… oisst-avhrr-… TRUE       \n\n\n\n2.3.2 Suppression des fichiers inutiles présents dans DATA/RAW\n\nCela concerne principalement les fichiers temporaires qui sont encore présents dans ce dossier alors qu’ils ont été supprimés sur le serveur.\nC’est la variable latest_finalized_date contenant la date du fichier finalisé le plus récent qui permet cette discrimination.\n\nCodedata_files_to_delete &lt;- data_files_loaded[!(data_files_loaded %in% data_files)]\nif (length(data_files_to_delete &gt; 0)) {\n  unlink(paste(\"DATA/RAW\", data_files_to_delete, sep = \"/\"))\n}\n\n\n\n2.3.3 Téléchargement des données SST (citère data_loaded == FALSE)\n\nCodeget_unloaded_data &lt;- function(data_filename, data_url) {\n  \n  file_path &lt;- paste(\"DATA/RAW\" , data_filename, sep = \"/\")\n  status_code &lt;- status_code(GET(data_url))\n  message(status_code)\n  if (status_code == 200) {\n    res &lt;- httr::GET(data_url,\n                     write_disk(file_path, overwrite = TRUE),\n                     progress()\n                    )\n  } else {\n    message(glue(\"The data for file {data_filename} are inaccessible\"))\n  }\n  \n}\n\ndata_files_unloaded &lt;- tib_expected |&gt; \n  dplyr::filter(!data_loaded)\ndata_filenames &lt;- data_files_unloaded$data_filename\ndata_urls &lt;- data_files_unloaded$data_url\npwalk(list(data_filenames, data_urls), get_unloaded_data)\n\n\n\n2.3.4 Comptabilisation réelle dans le tibble tib_sst\n\n\n# data_loaded renseigne sur la présence du fichier en local (dossier DATA)\n\ntib_sst &lt;- tib_expected\ndata_files &lt;- tib_sst$data_filename\ndata_files_loaded &lt;- list.files(path = \"DATA/RAW\", pattern = \"*.nc*\")\ntib_sst$data_loaded &lt;- (data_files %in% data_files_loaded)\n\nsaveRDS(tib_sst, \"DATA/tib_sst.RDS\")",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Données SST</span>"
    ]
  },
  {
    "objectID": "SST_001_recuperation_donnees.html#comptabilisation-des-fichiers-de-données",
    "href": "SST_001_recuperation_donnees.html#comptabilisation-des-fichiers-de-données",
    "title": "\n2  Récupération des données SST\n",
    "section": "\n2.3 Comptabilisation des fichiers de données",
    "text": "2.3 Comptabilisation des fichiers de données\n\n2.3.1 Comptabilisation théorique dans le tibble tib_expected\n\nLe tibble tib_expected contient les informations relatives à l’ensemble des données théoriquement entreposées sur le serveur (basées sur le protocole de production et de nommage des données)\n\ndate : date de production du fichier (temporaire ou finalisé)\n\ndata_url : url du fichier de données\ndata_filename : nom du fichier de données\n\nIl contient en plus une information permettant de savoir si le fichier a dèjà été téléchargé.\n\ndata_loaded : champ de type logique indiquant la présence des données du fichier en local dans le dossier DATA/RAW\n\n\n\nCodetib_expected &lt;- tibble(\n  date = seq(ymd(\"1981-09-01\"), latest_preliminary_date, by = \"days\")\n)\n\nurl_finalized_data &lt;- get_all_url(\n  start_date = ymd(\"1981-09-01\"),\n  end_date = latest_finalized_date,\n  is.preliminary = FALSE\n)\n  \nurl_preliminary_data &lt;- get_all_url(\n  start_date = latest_finalized_date + 1,\n  end_date = latest_preliminary_date,\n  is.preliminary = TRUE\n)\n\ntib_expected$data_url &lt;- c(url_finalized_data, url_preliminary_data)\n\ntib_expected$data_filename &lt;- tib_expected$data_url |&gt;\n  map(\\(x) {tail(stri_split_fixed(x, \"/\")[[1]], n = 1)}) |&gt; \n  unlist()\n\n\ndata_files &lt;- tib_expected$data_filename\ndata_files_loaded &lt;- list.files(path = \"DATA/RAW\", pattern = \"*.nc*\")\ndata_preliminary_loaded &lt;- list.files(\n  path = \"DATA/RAW\", pattern = \"*_preliminary.nc*\"\n)\ntib_expected$data_loaded &lt;- (data_files %in% data_files_loaded)\n\n\n\n2.3.2 Suppression des fichiers devenus inutiles\nCela concerne principalement les fichiers temporaires qui sont encore présents dans le dossier DATA/RAW alors qu’ils ont été supprimés sur le serveur.\nC’est la variable latest_finalized_date contenant la date du fichier finalisé le plus récent qui permet cette discrimination.\n\nCodedata_files_to_delete &lt;- data_files_loaded[!(data_files_loaded %in% data_files)]\nif (length(data_files_to_delete &gt; 0)) {\n  unlink(paste(\"DATA/RAW\", data_files_to_delete, sep = \"/\"))\n}\n\n\n\n2.3.3 Téléchargement des données SST\n\ncritère de sélection : data_loaded == FALSE\n\n\n\nCodeget_unloaded_data &lt;- function(data_filename, data_url) {\n  \n  file_path &lt;- paste(\"DATA/RAW\" , data_filename, sep = \"/\")\n  status_code &lt;- status_code(GET(data_url))\n  message(status_code)\n  if (status_code == 200) {\n    res &lt;- httr::GET(data_url,\n                     write_disk(file_path, overwrite = TRUE),\n                     progress()\n                    )\n  } else {\n    message(glue(\"The data for file {data_filename} are inaccessible\"))\n  }\n  \n}\n\ndata_files_unloaded &lt;- tib_expected |&gt; \n  dplyr::filter(!data_loaded)\ndata_filenames &lt;- data_files_unloaded$data_filename\ndata_urls &lt;- data_files_unloaded$data_url\npwalk(list(data_filenames, data_urls), get_unloaded_data)\n\n\n\n2.3.4 Comptabilisation réelle dans le tibble tib_sst\n\n\nCodetib_sst &lt;- tib_expected\ndata_files &lt;- tib_sst$data_filename\ndata_files_loaded &lt;- list.files(path = \"DATA/RAW\", pattern = \"*.nc*\")\ntib_sst$data_loaded &lt;- (data_files %in% data_files_loaded)\n\nsaveRDS(tib_sst, \"DATA/tib_sst.RDS\")",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Données SST</span>"
    ]
  },
  {
    "objectID": "SST_00_example.html",
    "href": "SST_00_example.html",
    "title": "\n2  Données SST du 1er décembre 2024\n",
    "section": "",
    "text": "2.1 Exploration du fichier NetCDF\nIl est possible de trouver de plus amples informations sur le traitement des fichiers netCDF avec R (« netCDF in R », s. d.)\nCodelibs &lt;- c(\"ncdf4\", \"tidyverse\", \"terra\", \"sf\")\n\n#install missing libraries\ninstalled_libs &lt;- libs %in% rownames(installed.packages())\nif (any(installed_libs == FALSE)) {\n  install.packages(libs[!installed_libs])\n}\n\n#load libraries\ninvisible(lapply(libs, library, character.only = TRUE))\nLa connexion au fichier NetCDF s’opère via la commande nc_open.\nGrâce à elle nous pouvons déjà voir quel type d’informations sont enregistrées.\n(nc &lt;- nc_open(\"DATA/RAW/oisst-avhrr-v02r01.20241201.nc\"))\n\nFile DATA/RAW/oisst-avhrr-v02r01.20241201.nc (NC_FORMAT_NETCDF4):\n\n     4 variables (excluding dimension variables):\n        short sst[lon,lat,zlev,time]   (Chunking: [1440,720,1,1])  (Compression: shuffle,level 4)\n            long_name: Daily sea surface temperature\n            units: Celsius\n            _FillValue: -999\n            add_offset: 0\n            scale_factor: 0.00999999977648258\n            valid_min: -300\n            valid_max: 4500\n        short anom[lon,lat,zlev,time]   (Chunking: [1440,720,1,1])  (Compression: shuffle,level 4)\n            long_name: Daily sea surface temperature anomalies\n            units: Celsius\n            _FillValue: -999\n            add_offset: 0\n            scale_factor: 0.00999999977648258\n            valid_min: -1200\n            valid_max: 1200\n        short err[lon,lat,zlev,time]   (Chunking: [1440,720,1,1])  (Compression: shuffle,level 4)\n            long_name: Estimated error standard deviation of analysed_sst\n            units: Celsius\n            _FillValue: -999\n            add_offset: 0\n            scale_factor: 0.00999999977648258\n            valid_min: 0\n            valid_max: 1000\n        short ice[lon,lat,zlev,time]   (Chunking: [1440,720,1,1])  (Compression: shuffle,level 4)\n            long_name: Sea ice concentration\n            units: %\n            _FillValue: -999\n            add_offset: 0\n            scale_factor: 0.00999999977648258\n            valid_min: 0\n            valid_max: 100\n\n     4 dimensions:\n        time  Size:1   *** is unlimited *** \n            long_name: Center time of the day\n            units: days since 1978-01-01 12:00:00\n        zlev  Size:1 \n            long_name: Sea surface height\n            units: meters\n            positive: down\n            actual_range: 0, 0\n        lat  Size:720 \n            long_name: Latitude\n            units: degrees_north\n            grids: Uniform grid from -89.875 to 89.875 by 0.25\n        lon  Size:1440 \n            long_name: Longitude\n            units: degrees_east\n            grids: Uniform grid from 0.125 to 359.875 by 0.25\n\n    37 global attributes:\n        Conventions: CF-1.6, ACDD-1.3\n        title: NOAA/NCEI 1/4 Degree Daily Optimum Interpolation Sea Surface Temperature (OISST) Analysis, Version 2.1 - Final\n        references: Reynolds, et al.(2007) Daily High-Resolution-Blended Analyses for Sea Surface Temperature (available at https://doi.org/10.1175/2007JCLI1824.1). Banzon, et al.(2016) A long-term record of blended satellite and in situ sea-surface temperature for climate monitoring, modeling and environmental studies (available at https://doi.org/10.5194/essd-8-165-2016). Huang et al. (2020) Improvements of the Daily Optimum Interpolation Sea Surface Temperature (DOISST) Version v02r01, submitted.Climatology is based on 1971-2000 OI.v2 SST. Satellite data: Pathfinder AVHRR SST, Navy AVHRR SST, and NOAA ACSPO SST. Ice data: NCEP Ice and GSFC Ice.\n        source: ICOADS, NCEP_GTS, GSFC_ICE, NCEP_ICE, Pathfinder_AVHRR, Navy_AVHRR, NOAA_ACSP\n        id: oisst-avhrr-v02r01.20241201.nc\n        naming_authority: gov.noaa.ncei\n        summary: NOAAs 1/4-degree Daily Optimum Interpolation Sea Surface Temperature (OISST) (sometimes referred to as Reynolds SST, which however also refers to earlier products at different resolution), currently available as version v02r01, is created by interpolating and extrapolating SST observations from different sources, resulting in a smoothed complete field. The sources of data are satellite (AVHRR) and in situ platforms (i.e., ships and buoys), and the specific datasets employed may change over time. At the marginal ice zone, sea ice concentrations are used to generate proxy SSTs.  A preliminary version of this file is produced in near-real time (1-day latency), and then replaced with a final version after 2 weeks. Note that this is the AVHRR-ONLY DOISST, available from Oct 1981, but there is a companion DOISST product that includes microwave satellite data, available from June 2002\n        cdm_data_type: Grid\n        history: Final file created using preliminary as first guess, and 3 days of AVHRR data. Preliminary uses only 1 day of AVHRR data.\n        date_modified: 2024-12-16T14:43:00Z\n        date_created: 2024-12-16T14:43:00Z\n        product_version: Version v02r01\n        processing_level: NOAA Level 4\n        institution: NOAA/National Centers for Environmental Information\n        creator_url: https://www.ncei.noaa.gov/\n        creator_email: oisst-help@noaa.gov\n        keywords: Earth Science &gt; Oceans &gt; Ocean Temperature &gt; Sea Surface Temperature\n        keywords_vocabulary: Global Change Master Directory (GCMD) Earth Science Keywords\n        platform: Ships, buoys, Argo floats, MetOp-A, MetOp-B\n        platform_vocabulary: Global Change Master Directory (GCMD) Platform Keywords\n        instrument: Earth Remote Sensing Instruments &gt; Passive Remote Sensing &gt; Spectrometers/Radiometers &gt; Imaging Spectrometers/Radiometers &gt; AVHRR &gt; Advanced Very High Resolution Radiometer\n        instrument_vocabulary: Global Change Master Directory (GCMD) Instrument Keywords\n        standard_name_vocabulary: CF Standard Name Table (v40, 25 January 2017)\n        geospatial_lat_min: -90\n        geospatial_lat_max: 90\n        geospatial_lon_min: 0\n        geospatial_lon_max: 360\n        geospatial_lat_units: degrees_north\n        geospatial_lat_resolution: 0.25\n        geospatial_lon_units: degrees_east\n        geospatial_lon_resolution: 0.25\n        time_coverage_start: 2024-12-01T00:00:00Z\n        time_coverage_end: 2024-12-01T23:59:59Z\n        metadata_link: https://doi.org/10.25921/RE9P-PT57\n        ncei_template_version: NCEI_NetCDF_Grid_Template_v2.0\n        comment: Data was converted from NetCDF-3 to NetCDF-4 format with metadata updates in November 2017.\n        sensor: Thermometer, AVHRR",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Un fichier SST</span>"
    ]
  },
  {
    "objectID": "SST_00_example.html#exploration-du-fichier-netcdf",
    "href": "SST_00_example.html#exploration-du-fichier-netcdf",
    "title": "\n2  Données SST du 1er décembre 2024\n",
    "section": "",
    "text": "2.1.1 Les dimensions\nles variables principales sont discriminées suivant plusieurs dimensions.\nIci, ce sont :\n\nlon : la longitude (de taille \\(1440=\\frac{360}{0.25}\\))\nlat : la latitude (de taille \\(720=\\frac{180}{0.25}\\))\nzlev : La hauteur de la surface de l’eau de mer\ntime : temps central de la journée\n\n\n\n\n\n\n\nNote\n\n\n\n\n\n\nLes longitudes sont ordonnées de l’Est vers l’Ouest en partant du méridien de Greenwich depuis la valeur \\(0.125\\) jusqu’à la valeur \\(0.125+1439*0.25=359.875\\)\nLes latitudes sont ordonnées du Sud au Nord dans l’array lat en partant du pôle Sud depuis la valeur \\(-90+0.125=-89.875\\) jusqu’à la valeur \\(-89.875+719*0.25=89.875\\)\n\n\n\n\nIl est possible d’avoir accès aux données des dimensions via la fonction ncvar_get et l’accès aux attributs avec la fonction ncatt_get\n\n# get info about latitudes\nlat &lt;- ncvar_get(nc, \"lat\")\n(lat_units &lt;- ncatt_get(nc, \"lat\", \"units\"))\n\n$hasatt\n[1] TRUE\n\n$value\n[1] \"degrees_north\"\n\n# get info about longitudes\nlon &lt;- ncvar_get(nc, \"lon\")\n(lon_units &lt;- ncatt_get(nc, \"lon\", \"units\"))\n\n$hasatt\n[1] TRUE\n\n$value\n[1] \"degrees_east\"\n\n# get info about time\ntime &lt;- ncvar_get(nc, \"time\")\n(time_units &lt;- ncatt_get(nc, \"time\", \"units\"))\n\n$hasatt\n[1] TRUE\n\n$value\n[1] \"days since 1978-01-01 12:00:00\"\n\ntime_as_date &lt;- as.Date(time, origin = \"1978-01-01 12:00:0\", tz = \"UTC\")\n# get info about zlev\nzlev &lt;- ncvar_get(nc, \"zlev\")\n(zlev_units &lt;- ncatt_get(nc, \"zlev\", \"units\"))\n\n$hasatt\n[1] TRUE\n\n$value\n[1] \"meters\"\n\n\n\n2.1.2 Les variables principales\nNous avons quatre variables stockées dans le fichier :\n\nsst : la température quotidienne de la surface de l’eau\nanom : les anomalies quotidiennes de température de surface de l’eau\nerr : estimated error standard deviation of analysed_sst\nice : la concentration en glace\n\n\n(nc_var &lt;- names(nc$var))\n\n[1] \"sst\"  \"anom\" \"err\"  \"ice\" \n\n# get info about variable attribute\nget_var_attribute &lt;- function(var, attribute) {\n  nc_var &lt;- names(nc$var)\n  if (!(var %in% nc_var)) {\n    message(paste(\"la variable\", var, \"est inexistante\"))\n  } else {\n  ln &lt;- ncatt_get(nc, var, attname = attribute)\n  ifelse(ln$hasatt, ln$value, paste(\"pas d'attribut \", attribute))\n  }\n}\n\n# long names\nget_var_long_name &lt;- function() {\n  vapply(\n  nc_var, \n  get_var_attribute, \n  FUN.VALUE = character(1), \n  \"long_name\"\n  )\n}\n((get_var_long_name()))\n\n                                                 sst \n                     \"Daily sea surface temperature\" \n                                                anom \n           \"Daily sea surface temperature anomalies\" \n                                                 err \n\"Estimated error standard deviation of analysed_sst\" \n                                                 ice \n                             \"Sea ice concentration\" \n\n# source\nget_var_units &lt;- function() {\n  vapply(\n  nc_var, \n  get_var_attribute, \n  FUN.VALUE = character(1), \n  \"units\"\n  )\n}\n((get_var_units()))\n\n      sst      anom       err       ice \n\"Celsius\" \"Celsius\" \"Celsius\"       \"%\" \n\n# fill value\nget_var_fill_value &lt;- function() {\n  vapply(\n  nc_var, \n  get_var_attribute, \n  FUN.VALUE = numeric(1), \n  \"_FillValue\"\n  )\n}\n((get_var_fill_value()))\n\n sst anom  err  ice \n-999 -999 -999 -999 \n\n\n\n2.1.3 Les attributs globaux du fichier\n\natt &lt;- c(\"title\", \"institution\", \"source\", \"references\", \"history\", \"Conventions\") \nget_global_attribute &lt;- function(att) {\n  ncatt_get(nc, 0, att)$value\n}\n(global_attributes &lt;- vapply(att, get_global_attribute, FUN.VALUE = character(1)))\n\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        title \n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \"NOAA/NCEI 1/4 Degree Daily Optimum Interpolation Sea Surface Temperature (OISST) Analysis, Version 2.1 - Final\" \n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  institution \n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \"NOAA/National Centers for Environmental Information\" \n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       source \n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \"ICOADS, NCEP_GTS, GSFC_ICE, NCEP_ICE, Pathfinder_AVHRR, Navy_AVHRR, NOAA_ACSP\" \n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   references \n\"Reynolds, et al.(2007) Daily High-Resolution-Blended Analyses for Sea Surface Temperature (available at https://doi.org/10.1175/2007JCLI1824.1). Banzon, et al.(2016) A long-term record of blended satellite and in situ sea-surface temperature for climate monitoring, modeling and environmental studies (available at https://doi.org/10.5194/essd-8-165-2016). Huang et al. (2020) Improvements of the Daily Optimum Interpolation Sea Surface Temperature (DOISST) Version v02r01, submitted.Climatology is based on 1971-2000 OI.v2 SST. Satellite data: Pathfinder AVHRR SST, Navy AVHRR SST, and NOAA ACSPO SST. Ice data: NCEP Ice and GSFC Ice.\" \n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      history \n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \"Final file created using preliminary as first guess, and 3 days of AVHRR data. Preliminary uses only 1 day of AVHRR data.\" \n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Conventions \n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \"CF-1.6, ACDD-1.3\"",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Un fichier SST</span>"
    ]
  },
  {
    "objectID": "SST_00_example.html#exploration-des-variables",
    "href": "SST_00_example.html#exploration-des-variables",
    "title": "\n2  Données SST du 1er décembre 2024\n",
    "section": "\n2.2 Exploration des variables",
    "text": "2.2 Exploration des variables\n\nnc_var &lt;- names(nc$var)\n\nnc_charge_var &lt;- function(var) {\n  nc_var &lt;- ncvar_get(nc = nc, varid = var )\n  envir &lt;- globalenv()\n  assign(var, nc_var, envir = envir)\n}\n\nwalk(nc_var, nc_charge_var)\n\nLa variable sst est enregistrée en tant que matrix, array avec les dimensions 1440, 720\n\nLa longitude correspond à la 1ère dimension (lignes de la matrice)\nLa latitude correspond à la 2ème dimension (colonnes de la matrice)\nLe vecteur associé est obtenu en parcourant d’abord les 1440 longitudes d’un parallèle avant de passer à la latitude suivante.\n\n\nlonlat &lt;- expand.grid(lon, lat)\ndf_sst &lt;- cbind(lonlat, as.vector(sst))\nnames(df_sst) &lt;- c(\"lon\", \"lat\", \"sst\")\nhead(df_sst)\n\n    lon     lat sst\n1 0.125 -89.875  NA\n2 0.375 -89.875  NA\n3 0.625 -89.875  NA\n4 0.875 -89.875  NA\n5 1.125 -89.875  NA\n6 1.375 -89.875  NA",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Un fichier SST</span>"
    ]
  },
  {
    "objectID": "SST_00_example.html#affichage-de-la-carte-des-données-sst",
    "href": "SST_00_example.html#affichage-de-la-carte-des-données-sst",
    "title": "\n2  Données SST du 1er décembre 2024\n",
    "section": "\n2.3 Affichage de la carte des données sst",
    "text": "2.3 Affichage de la carte des données sst\nAvec positionnement en rouge du point de test donné en exemple :\n\n#|label: plot_sst\n\ndf_sst |&gt; \n  ggplot(aes(x = lon, y = lat, color = sst)) + \n  geom_point(size = 0.5) +\n  coord_fixed(expand = FALSE) +\n  scale_colour_distiller(palette = \"RdBu\") +\n  labs(\n    x = NULL,\n    y = NULL,\n    title = \"Sea Surface Temperature\",\n    subtitle = time_as_date,\n    caption = \"Dataset: NOAA OISST V2.1\",\n    color = \"°C\"\n  )",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Un fichier SST</span>"
    ]
  },
  {
    "objectID": "SST_00_example.html#calcul-de-moyenne-globale",
    "href": "SST_00_example.html#calcul-de-moyenne-globale",
    "title": "\n2  Données SST du 1er décembre 2024\n",
    "section": "\n2.4 Calcul de moyenne globale",
    "text": "2.4 Calcul de moyenne globale\nIl semble qu’il faille appliquer un poids fonction de \\(\\alpha\\) en radians pour pondérer les mesures de surface en fonction de la latitude considérée.\nPour calculer ces poids j’ai construit tous les polygones “carrés” de 0.25° de côté suivant un même méridien.\nCes polygones ont pour centre les coordonnées (longitude et latitude) de la mesure SST correspondante.\nJ’ai ensuite calculé les aires de ces polygones avec le système de coordonnées de référence EPSG:4326 (WGS84).\nLes poids relatifs à chaque mesure ont été fixés comme étant les ratio des aires obtenues avec celle de la plus grande aire (aire du polygone situé à l’équateur).\n\n2.4.1 Calcul des poids à affecter aux mesures suivant la latitude associée\n\n# fonction génératrice de \"carré géographique\" de n degrés de côté\n# le point de base (lon, lat) est le point inférieur gauche. \n\npolygone_geo &lt;- function(lon, lat, n) {\n  polygon_list &lt;- list(rbind(\n    c(lon, lat),\n    c(lon + n, lat),\n    c(lon + n, lat + n),\n    c(lon, lat + n),\n    c(lon, lat)\n  ))\n  st_polygon(polygon_list)\n}\n\npolygone_sfc &lt;- seq(-90, 89.75, by = 0.25) |&gt;\n  map(\\(x) polygone_geo(lon = 0, lat = x, n = 0.25)) |&gt; \n  st_sfc(crs = \"EPSG:4326\")\n\narea_weights &lt;- as.numeric(st_area(polygone_sfc) / max(st_area(polygone_sfc)))\nhead(area_weights)\n\n[1] 0.002181655 0.006544922 0.010908066 0.015271001 0.019633646 0.023995917\n\n\n\ndf_area_weights &lt;- expand.grid(lon, area_weights)\nnames(df_area_weights) &lt;- c(\"lon\", \"w\")\nw &lt;- df_area_weights$w\ndf_sst_weights &lt;- cbind(df_sst, w)\n\n# moyenne pondérée globale\nsst_weighted_mean &lt;- df_sst_weights |&gt; \n  summarize(wm_sst = weighted.mean(sst, w, na.rm = TRUE))\nsst_weighted_mean\n\n    wm_sst\n1 18.44787\n\n# moyenne pondérée entre -60°S et +60°N\ndf_sst_60S_60N &lt;- df_sst_weights |&gt; \n  filter(lat &gt;= -60 & lat &lt;= 60)\nsst_weighted_mean_60S_60N &lt;- df_sst_60S_60N |&gt; \n  summarize(wm_sst_60S_60N = weighted.mean(sst, w, na.rm = TRUE))\nsst_weighted_mean_60S_60N\n\n  wm_sst_60S_60N\n1       20.65579\n\n\nSi nous souhaitons centrer la carte sur le méridien de Greenwich, il est nécessaire de translater les longitudes.\n\n#|label: plot_sst_greenwich\n\ndf_sst |&gt; \n  mutate(lon = if_else(lon &gt; 180, lon - 360, lon)) |&gt; \n  ggplot(aes(x = lon, y = lat, fill = sst)) + \n  geom_raster() +\n  scale_fill_gradient2(\n    low = \"darkblue\",\n    mid = \"white\",\n    high = \"darkred\",\n    midpoint = 15\n  ) +\n  coord_fixed(expand = FALSE) +\n  #scale_colour_distiller(palette = \"RdBu\") +\n  labs(\n    x = NULL,\n    y = NULL,\n    title = \"Sea Surface Temperature\",\n    subtitle = paste0(\n      time_as_date,\n      \" - mean global = \",\n      round(sst_weighted_mean, 2),\n      \" °Celsius\",\n      \" | \",\n      \" mean World(60°S-60°N) = \",\n      round(sst_weighted_mean_60S_60N, 2),\n      \" °Celsius\"\n    ),\n    caption = \"Dataset: NOAA OISST V2.1\",\n    fill = \"°C\",\n  ) +\n  theme(\n    axis.text = element_blank(),\n    axis.ticks = element_blank(),\n    # panel.background = element_rect(fill = \"black\"),\n    # plot.background = element_rect(fill = \"black\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n« netCDF in R ». s. d. https://pjbartlein.github.io/REarthSysSci/netCDF.html.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Un fichier SST</span>"
    ]
  },
  {
    "objectID": "SST_01_recuperation_donnees.html",
    "href": "SST_01_recuperation_donnees.html",
    "title": "\n3  Récupération des données SST\n",
    "section": "",
    "text": "3.1 Chargement de packages nécessaires\nCodelibs &lt;- c(\"glue\", \"httr\", \"tidyverse\", \"terra\", \"ncdf4\", \"stringi\", \"gt\")\n\ninstalled_libs &lt;- libs %in% rownames(installed.packages())\nif (any(installed_libs == FALSE)) {\n  install.packages(libs[!installed_libs])\n}\n\ninvisible(lapply(libs, library, character.only = TRUE))",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Données SST</span>"
    ]
  },
  {
    "objectID": "SST_01_recuperation_donnees.html#chargement-de-packages-nécessaires",
    "href": "SST_01_recuperation_donnees.html#chargement-de-packages-nécessaires",
    "title": "\n3  Récupération des données SST\n",
    "section": "",
    "text": "httr pour le téléchargement des fichiers de données\n\ntidyverse pour les fonctionnalités offertes par\n\n\nggplot2,\n\nlubridate pour la gestion du temps,\n\npurrr, entre autres.\n\n\n\nterra,\n\nncdf4 pour la gestion des fichiers NetCDF,\n\nstringi pour la fonction stri_sub\n\ngt pour la représentation tabulaire",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Données SST</span>"
    ]
  },
  {
    "objectID": "SST_01_recuperation_donnees.html#décompte-des-fichiers-exploitables",
    "href": "SST_01_recuperation_donnees.html#décompte-des-fichiers-exploitables",
    "title": "\n3  Récupération des données SST\n",
    "section": "\n3.2 Décompte des fichiers exploitables",
    "text": "3.2 Décompte des fichiers exploitables\nLes fichiers de données NectCDF temporaires ont le suffixe “_preliminary”.\nLes autres ne possèdent pas ce suffixe.\nLe premier fichier NetCDF exploitable date du 1er septembre 1981. En date du Sys.Date() nous allons déterminer :\n\nla date du dernier fichier finalisé disponible\nla date du dernier fichier temporaire disponible\nle nombre total de fichiers finalisés\nle nombre total de fichiers temporaires\n\n\n3.2.1 Détermination de l’url du fichier de données .nc\n\n\nen fonction de la date,\net du statut (finalisé ou temporaire)\n\n\nCodeyyyymm &lt;- function(date) {\n  return(gsub(\"-\", \"\", stri_sub(date, 1, 7)))\n}\n\nyyyymmdd &lt;- function(date) { \n  return(gsub(\"-\", \"\", date))\n}\n\nget_url &lt;- function(date, is.preliminary = FALSE) {\n  \n  url_root &lt;- \"https://www.ncei.noaa.gov/data/sea-surface-temperature-optimum-interpolation/v2.1/access/avhrr\"\n  url_folder &lt;- paste(url_root, yyyymm(date), sep = \"/\")\n  file_prefix &lt;- \"oisst-avhrr-v02r01.\"\n  file_suffix &lt;- if_else(is.preliminary, \"_preliminary.nc\", \".nc\")\n  url_file &lt;- paste0(file_prefix, yyyymmdd(date), file_suffix)\n  return(paste(url_folder, url_file, sep = '/'))\n  \n}\n\nget_all_url &lt;- function(start_date, end_date, is.preliminary = FALSE) {\n  \n  seq_days &lt;- seq(start_date, end_date, by = \"days\")\n  all_url &lt;- sapply(seq_days, get_url, is.preliminary = is.preliminary)\n  return(all_url)\n  \n}\n\n\n\n3.2.2 Datation des derniers fichiers (temporaire et finalisé)\nPrincipe :\nOn recherche à partir de la date du jour la présence des données aux urls que l’on aura calculées par ailleurs avec la fonction get_url. Si la page sollicitée est présente on a fini.\nSinon on passe au jour précédent, et ainsi de suite si nécessaire, jusqu’à tomber sur un code réponse http de valeur 200.\n\n\n\n\n\n\nNote\n\n\n\nLes données collectées qualifiées de temporaires sont enregistrées dans un fichier avec l’extension _preliminary.nc le temps que les données soient vérifiées et validées.\nCette opération se déroule sur un délai d’approximativement 2 semaines à partir de la date de collecte des données.\n\n\n\nCodeget_latest_date &lt;- function(init_date, increment = -1, is.preliminary) {\n  \n  date &lt;- init_date\n  http_200_status_OK &lt;- FALSE\n  while (!http_200_status_OK) {\n    url &lt;- get_url(date = date, is.preliminary = is.preliminary)\n    http_status_code &lt;- status_code(GET(url))\n    if (http_status_code == 404) { \n      date &lt;- date + increment\n    } else {\n      if (http_status_code == 200) { \n        http_200_status_OK &lt;- TRUE \n      }\n    }\n  }\n  return(date)\n}\n\nlatest_preliminary_date &lt;- get_latest_date(\n  init_date = Sys.Date(),\n  is.preliminary = TRUE\n)\n\nlatest_finalized_date &lt;- get_latest_date(\n  init_date = Sys.Date() - 14,\n  is.preliminary = FALSE\n)\n\n\n\n\n\n\n\n\nNote\n\n\n\nSi des fichiers preliminary se retrouvent encore parmi des fichiers finalisés, parce qu’ils n’auront pas encore été traités, alors les décomptes de fichiers finalisés et temporaires seront inexacts.\n\n\n\nCodedata_files_count &lt;- function(start_date, end_date) {\n  \n  lubridate::interval(start_date, end_date) %/% days(1) + 1\n\n}\n\nnc_files_count &lt;- data_files_count(ymd(\"1981-09-01\"), latest_finalized_date)\npreliminary_files_count &lt;- data_files_count(ymd(\"1981-09-01\"), latest_preliminary_date)\n\ntib_summary &lt;- tibble(\n  file_extension = c(\".nc\", \"_preliminary.nc\"),\n  file_type = c(\"Finalisé\", \"Temporaire\"),\n  latest_date = c(latest_finalized_date, latest_preliminary_date),\n  file_count  = c(nc_files_count, preliminary_files_count)\n)\n\ngt_summary &lt;- gt(tib_summary) |&gt; \n  tab_header(\n    title = md(\"**Informations relatives aux fichiers de données**\"),\n    subtitle = md(\"(Valeurs théoriques)\")\n  ) |&gt; \n  tab_footnote(\n    footnote = md(\"Première collecte quotidienne datée du **01/09/1981**\"),\n    locations = cells_body(\n      columns = file_count, rows = all()\n    )\n  ) |&gt; \n  tab_footnote(\n    footnote = md(\"Dates **estimées** selon le protocole de traitement des données\"),\n    locations = cells_body(\n      columns = latest_date, rows = all()\n    )\n  )\n\ngt_summary\n\n\n\n\n\n\nInformations relatives aux fichiers de données\n\n\n(Valeurs théoriques)\n\n\nfile_extension\nfile_type\nlatest_date\nfile_count\n\n\n\n\n.nc\nFinalisé\n\n1 2024-12-05\n\n2 15802\n\n\n_preliminary.nc\nTemporaire\n\n1 2024-12-19\n\n2 15816\n\n\n\n\n\n1 Dates estimées selon le protocole de traitement des données\n\n\n\n2 Première collecte quotidienne datée du 01/09/1981",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Données SST</span>"
    ]
  },
  {
    "objectID": "SST_01_recuperation_donnees.html#comptabilisation-des-fichiers-de-données",
    "href": "SST_01_recuperation_donnees.html#comptabilisation-des-fichiers-de-données",
    "title": "\n3  Récupération des données SST\n",
    "section": "\n3.3 Comptabilisation des fichiers de données",
    "text": "3.3 Comptabilisation des fichiers de données\n\n3.3.1 Comptabilisation théorique dans le tibble tib_expected\n\nLe tibble tib_expected contient les informations relatives à l’ensemble des données théoriquement entreposées sur le serveur (basées sur le protocole de production et de nommage des données)\n\ndate : date de production du fichier (temporaire ou finalisé)\n\ndata_url : url du fichier de données\ndata_filename : nom du fichier de données\n\nIl contient en plus une information permettant de savoir si le fichier a dèjà été téléchargé.\n\ndata_loaded : champ de type logique indiquant la présence des données du fichier en local dans le dossier DATA/RAW\n\n\n\nCodetib_expected &lt;- tibble(\n  date = seq(ymd(\"1981-09-01\"), latest_preliminary_date, by = \"days\")\n)\n\nurl_finalized_data &lt;- get_all_url(\n  start_date = ymd(\"1981-09-01\"),\n  end_date = latest_finalized_date,\n  is.preliminary = FALSE\n)\n  \nurl_preliminary_data &lt;- get_all_url(\n  start_date = latest_finalized_date + 1,\n  end_date = latest_preliminary_date,\n  is.preliminary = TRUE\n)\n\ntib_expected$data_url &lt;- c(url_finalized_data, url_preliminary_data)\n\ntib_expected$data_filename &lt;- tib_expected$data_url |&gt;\n  map(\\(x) {tail(stri_split_fixed(x, \"/\")[[1]], n = 1)}) |&gt; \n  unlist()\n\n\ndata_files &lt;- tib_expected$data_filename\ndata_files_loaded &lt;- list.files(path = \"DATA/RAW\", pattern = \"*.nc*\")\ndata_preliminary_loaded &lt;- list.files(\n  path = \"DATA/RAW\", pattern = \"*_preliminary.nc*\"\n)\ntib_expected$data_loaded &lt;- (data_files %in% data_files_loaded)\n\n\n\n3.3.2 Suppression des fichiers devenus inutiles\nCela concerne principalement les fichiers temporaires qui sont encore présents dans le dossier DATA/RAW alors qu’ils ont été supprimés sur le serveur.\nC’est la variable latest_finalized_date contenant la date du fichier finalisé le plus récent qui permet cette discrimination.\n\nCodedata_files_to_delete &lt;- data_files_loaded[!(data_files_loaded %in% data_files)]\nif (length(data_files_to_delete &gt; 0)) {\n  unlink(paste(\"DATA/RAW\", data_files_to_delete, sep = \"/\"))\n}\n\n\n\n3.3.3 Téléchargement des données SST\n\ncritère de sélection : data_loaded == FALSE\n\n\n\nCodeget_unloaded_data &lt;- function(data_filename, data_url) {\n  \n  file_path &lt;- paste(\"DATA/RAW\" , data_filename, sep = \"/\")\n  status_code &lt;- status_code(GET(data_url))\n  message(status_code)\n  if (status_code == 200) {\n    res &lt;- httr::GET(data_url,\n                     write_disk(file_path, overwrite = TRUE),\n                     progress()\n                    )\n  } else {\n    message(glue(\"The data for file {data_filename} are inaccessible\"))\n  }\n  \n}\n\ndata_files_unloaded &lt;- tib_expected |&gt; \n  dplyr::filter(!data_loaded)\ndata_filenames &lt;- data_files_unloaded$data_filename\ndata_urls &lt;- data_files_unloaded$data_url\npwalk(list(data_filenames, data_urls), get_unloaded_data)\n\n\n\n3.3.4 Comptabilisation réelle dans le tibble tib_sst\n\n\nCodetib_sst &lt;- tib_expected\ndata_files &lt;- tib_sst$data_filename\ndata_files_loaded &lt;- list.files(path = \"DATA/RAW\", pattern = \"*.nc*\")\ntib_sst$data_loaded &lt;- (data_files %in% data_files_loaded)\n\nsaveRDS(tib_sst, \"DATA/tib_sst.RDS\")",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Données SST</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "“netCDF in r.” n.d. https://pjbartlein.github.io/REarthSysSci/netCDF.html.",
    "crumbs": [
      "References"
    ]
  }
]
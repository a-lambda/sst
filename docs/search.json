[
  {
    "objectID": "SST_001_recuperation_donnees.html",
    "href": "SST_001_recuperation_donnees.html",
    "title": "\n2  Récupération des données SST\n",
    "section": "",
    "text": "2.1 Chargement de packages nécessaires\nlibs &lt;- c(\"glue\", \"httr\", \"tidyverse\", \"terra\", \"ncdf4\", \"stringi\")\n\n#install missing libraries\ninstalled_libs &lt;- libs %in% rownames(installed.packages())\nif (any(installed_libs == FALSE)) {\n  install.packages(libs[!installed_libs])\n}\n\n#load libraries\ninvisible(lapply(libs, library, character.only = TRUE))",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Données SST</span>"
    ]
  },
  {
    "objectID": "SST_001_recuperation_donnees.html#chargement-de-packages-nécessaires",
    "href": "SST_001_recuperation_donnees.html#chargement-de-packages-nécessaires",
    "title": "\n2  Récupération des données SST\n",
    "section": "",
    "text": "httr pour le téléchargement des fichiers de données\n\ntidyverse pour les fonctionnalités offertes par\n\n\nggplot2,\n\nlubridate pour la gestion du temps,\n\npurrr, entre autres.\n\n\n\nterra,\n\nncdf4 pour la gestion des fichiers NetCDF,\n\nstringi pour la fonction stri_sub",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Données SST</span>"
    ]
  },
  {
    "objectID": "SST_001_recuperation_donnees.html#décompte-des-fichiers-exploitables",
    "href": "SST_001_recuperation_donnees.html#décompte-des-fichiers-exploitables",
    "title": "\n2  Récupération des données SST\n",
    "section": "\n2.2 Décompte des fichiers exploitables",
    "text": "2.2 Décompte des fichiers exploitables\nLes fichiers de données NectCDF temporaires ont le suffixe “_preliminary”.\nLes autres ne possèdent pas ce suffixe.\nLe premier fichier NetCDF exploitable date du 1er septembre 1981. En date du Sys.Date() nous allons déterminer :\n\nla date du dernier fichier finalisé disponible\nla date du dernier fichier temporaire disponible\nle nombre total de fichiers finalisés\nle nombre total de fichiers temporaires\n\n\nyyyymm &lt;- function(date) {\n  return(gsub(\"-\", \"\", stri_sub(date, 1, 7)))\n}\n\nyyyymmdd &lt;- function(date) { \n  return(gsub(\"-\", \"\", date))\n}\n\n\nurl_data &lt;- function(date, is.preliminary = FALSE) {\n  \n  url_root &lt;- \"https://www.ncei.noaa.gov/data/sea-surface-temperature-optimum-interpolation/v2.1/access/avhrr\"\n  file_prefix &lt;- \"oisst-avhrr-v02r01.\" \n  file_suffix &lt;- ifelse(is.preliminary, \"_preliminary.nc\", \".nc\")\n  return(\n    paste(\n      url_root, \n      yyyymm(date),\n      paste0(file_prefix, yyyymmdd(date), file_suffix),\n      sep = \"/\"  \n    )\n  )\n  \n}\n\n\nget_newest_date &lt;- function(is.preliminary) {\n  \n  init_date &lt;- as.Date(\n    ifelse(is.preliminary, Sys.Date(), Sys.Date() - 14)\n  )\n  date &lt;- init_date\n  http_200_status_OK &lt;- FALSE\n  while (!http_200_status_OK) {\n    url &lt;- url_data(date = date, is.preliminary = is.preliminary)\n    http_status_code &lt;- status_code(\n      GET(url)\n    )\n    if (http_status_code == 404) { \n      date &lt;- date - 1\n    } else {\n      if (http_status_code == 200) { \n        http_200_status_OK &lt;- TRUE \n      }\n    }\n  }\n  return(date)\n}\n\nnewest_preliminary_date &lt;- get_newest_date(is.preliminary = TRUE)\nnewest_finalized_date &lt;- get_newest_date(is.preliminary = FALSE)\n\n\ndata_files_count &lt;- function(start_date, end_date) {\n  \n  lubridate::interval(start_date, end_date) %/% days(1) + 1\n\n}\n\nnc_files_count &lt;- data_files_count(ymd(\"1981-09-01\"), newest_finalized_date)\npreliminary_files_count &lt;- data_files_count(ymd(\"1981-09-01\"), newest_preliminary_date)\n\npaste0(\"Dernier fichier finalisé daté du : \", newest_finalized_date)\n\n[1] \"Dernier fichier finalisé daté du : 2024-11-30\"\n\npaste0(\"Dernier fichier temporaire daté du : \", newest_preliminary_date)\n\n[1] \"Dernier fichier temporaire daté du : 2024-12-14\"\n\npaste0(\"Nombre de fichiers finalisés : \", nc_files_count)\n\n[1] \"Nombre de fichiers finalisés : 15797\"\n\npaste0(\"Nombre de fichiers temporaires : \", preliminary_files_count)\n\n[1] \"Nombre de fichiers temporaires : 15811\"",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Données SST</span>"
    ]
  },
  {
    "objectID": "SST_001_recuperation_donnees.html#remplissage-de-la-table-des-fichiers-de-données",
    "href": "SST_001_recuperation_donnees.html#remplissage-de-la-table-des-fichiers-de-données",
    "title": "\n2  Récupération des données SST\n",
    "section": "\n2.3 Remplissage de la table des fichiers de données",
    "text": "2.3 Remplissage de la table des fichiers de données\nCréation d’un tibble tib_sst composée des colonnes suivantes :\n\ndate : date de récupération des données\ndata_filename : nom local du fichier de données\ndata_url : url permettant d’accéder aux données pour une date donnée\n\nRemarque :\nLa problématique consiste à mettre à jour au fil de l’eau les données qui sont initialement enregistrées dans un fichier avec l’extension **preliminary.nc” le temps que les données soient “validées”. Cette opération se déroule sur un délai d’approximativement 2 semaines à partir de la récupération des données.\n\n# Les mesures ont démarré le 1er septembre 1981\n# \ntib_expected &lt;- tibble(\n  date = seq(ymd(\"1981-09-01\"), newest_preliminary_date, by = \"days\")\n)\n\nget_data_url &lt;- function(start_date, end_date, is.preliminary) {\n  \n  seq_days &lt;- seq(start_date, end_date, by = \"days\")\n  url_folder &lt;- yyyymm(seq_days)\n  file_prefix &lt;- \"oisst-avhrr-v02r01.\"\n  file_suffix &lt;- if_else(is.preliminary, \"_preliminary.nc\", \".nc\")\n  url_file &lt;- paste0(file_prefix, yyyymmdd(seq_days), file_suffix)\n  return(list(url_folder, url_file))\n  \n}\n  \nurl_finalized_data &lt;- get_data_url(\n  start_date = ymd(\"1981-09-01\"),\n  end_date = newest_finalized_date,\n  is.preliminary = FALSE\n)\n  \nurl_preliminary_data &lt;- get_data_url(\n  start_date = newest_finalized_date + 1,\n  end_date = newest_preliminary_date,\n  is.preliminary = TRUE\n)\n\ntib_expected$data_filename &lt;- c(\n  url_finalized_data[[2]], \n  url_preliminary_data[[2]]\n)\n\nurl_root &lt;- \"https://www.ncei.noaa.gov/data/sea-surface-temperature-optimum-interpolation/v2.1/access/avhrr/\"\n  \nget_data_urls &lt;- function(url_parts) {\n  \n  return(paste(url_root, url_parts[[1]], url_parts[[2]], sep = \"/\"))\n         \n} \n\ntib_expected$data_url &lt;- c(\n  get_data_urls(url_finalized_data),\n  get_data_urls(url_preliminary_data)\n)\n\nLe champ data_files_loaded de type logique permet de connaître la liste des fichiers de données déjà présents dans le dossier DATA\n\n# data_loaded renseigne sur la présence du fichier en local (dossier DATA)\n\ndata_files &lt;- tib_expected$data_filename\ndata_files_loaded &lt;- list.files(path = \"DATA\", pattern = \"*.nc*\")\ndata_preliminary_loaded &lt;- list.files(\n  path = \"DATA\", pattern = \"*_preliminary.nc*\"\n)\ntib_expected$data_loaded &lt;- (data_files %in% data_files_loaded)\n\n\ndata_files_to_delete &lt;- data_files_loaded[!(data_files_loaded %in% data_files)]\nif (length(data_files_to_delete &gt; 0)) {\n  unlink(paste(\"DATA\", data_files_to_delete, sep = \"/\"))\n}",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Données SST</span>"
    ]
  },
  {
    "objectID": "SST_001_recuperation_donnees.html#téléchargement-des-données-sst-si-nécessaire-avec-data_loaded-false",
    "href": "SST_001_recuperation_donnees.html#téléchargement-des-données-sst-si-nécessaire-avec-data_loaded-false",
    "title": "\n2  Récupération des données SST\n",
    "section": "\n2.4 Téléchargement des données SST (si nécessaire avec data_loaded == FALSE)",
    "text": "2.4 Téléchargement des données SST (si nécessaire avec data_loaded == FALSE)\n\nget_unloaded_data &lt;- function(data_filename, data_url) {\n  \n  file_path &lt;- paste(\"DATA\" , data_filename, sep = \"/\")\n  status_code &lt;- status_code(GET(data_url))\n  message(status_code)\n  if (status_code == 200) {\n    res &lt;- httr::GET(data_url,\n                     write_disk(file_path, overwrite = TRUE),\n                     progress()\n                    )\n  } else {\n    message(glue(\"The data for file {data_filename} are inaccessible\"))\n  }\n  \n}\n\ndata_files_unloaded &lt;- tib_expected |&gt; \n  dplyr::filter(!data_loaded)\n\ndata_filenames &lt;- data_files_unloaded$data_filename\ndata_urls &lt;- data_files_unloaded$data_url\n\npwalk(list(data_filenames, data_urls), get_unloaded_data)\n\n\n# data_loaded renseigne sur la présence du fichier en local (dossier DATA)\n\ntib_sst &lt;- tib_expected\ndata_files &lt;- tib_sst$data_filename\ndata_files_loaded &lt;- list.files(path = \"DATA\", pattern = \"*.nc*\")\ntib_sst$data_loaded &lt;- (data_files %in% data_files_loaded)\n\nsaveRDS(tib_sst, \"DATA/tib_sst.RDS\")",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Données SST</span>"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "1.1 Présentation des données exploitées\nLe NOAA1 présente au travail du portail du NCEI2 un ensemble de données environnementales.\nNous allons ici considérer les relevés quotidiens de la température de surface de l’eau de mer au niveau mondial.\nLes données brutes recensées par différentes sondes (satellites, navires, bouées) sur un maillage régulier de 0,25° par 0,25° sont combinées et les lacunes sont comblées par interpolation.\nCes données traitées sont ensuite mises à disposition sur le site de la NOAA sour forme de fichiers NetCDF.\nElles sont accessibles ici sous la rubrique sea-surface-temperature-optimum-interpolation\nDes informations complémentaires sur cet ensemble de données sont disponibles ici.\nNous allons tenter de générer le même type de graphes temporels que ceux disponibles sur le site de Climate Reanalyzer et accessibles sur la page Daily Sea Surface Temperature.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "intro.html#footnotes",
    "href": "intro.html#footnotes",
    "title": "1  Introduction",
    "section": "",
    "text": "National Oceanic and Atmospheric Administration↩︎\nNational Centers for Environmental Information↩︎",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "SST_02_timeseries.html",
    "href": "SST_02_timeseries.html",
    "title": "\n3  Données temporelles\n",
    "section": "",
    "text": "3.1 chargement librairies utiles\nlibs &lt;- c(\n  \"ncdf4\",\n  \"tidyverse\",\n  \"data.table\",\n  \"jsonlite\",\n  \"tictoc\",\n  \"fpp3\",\n  \"stringi\"\n)\n#install missing libraries\ninstalled_libs &lt;- libs %in% rownames(installed.packages())\nif (any(installed_libs == FALSE)) {\n  install.packages(libs[!installed_libs])\n}\n#load libraries\ninvisible(lapply(libs, library, character.only = TRUE))",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Données temporelles</span>"
    ]
  },
  {
    "objectID": "SST_02_timeseries.html#fonctions-de-base-peut-être-disponibles-dans-lubridate",
    "href": "SST_02_timeseries.html#fonctions-de-base-peut-être-disponibles-dans-lubridate",
    "title": "\n3  Données temporelles\n",
    "section": "\n3.2 fonctions de base (peut-être disponibles dans lubridate)",
    "text": "3.2 fonctions de base (peut-être disponibles dans lubridate)\n\nyyyymm &lt;- function(date) {\n  return(gsub(\"-\", \"\", stri_sub(date, 1, 7)))\n}\n\nyyyymmdd &lt;- function(date) { \n  return(gsub(\"-\", \"\", Sys.Date()))\n}",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Données temporelles</span>"
    ]
  },
  {
    "objectID": "SST_02_timeseries.html#weights-to-apply-to-square-of-0.25x0.25-along-the-latitude",
    "href": "SST_02_timeseries.html#weights-to-apply-to-square-of-0.25x0.25-along-the-latitude",
    "title": "\n3  Données temporelles\n",
    "section": "\n3.3 weights to apply to square of 0.25°x0.25° along the latitude",
    "text": "3.3 weights to apply to square of 0.25°x0.25° along the latitude\n\narea_weights &lt;- fread(\n  file = \"area_weights.csv\",\n  dec = \",\"\n) |&gt; pull( w )\n# matrix_area_weights &lt;- matrix(rep(area_weights, 1440), nrow = 1440, byrow = TRUE)\n# wmean &lt;- weighted.mean(sst, matrix_area_weights, na.rm = TRUE)\n# wmean_60_60 &lt;- weighted.mean(sst[,121:600], matrix_area_weights[,121:600], na.rm = TRUE)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Données temporelles</span>"
    ]
  },
  {
    "objectID": "SST_02_timeseries.html#fonctions-de-calcul-de-moyenne-pondérée",
    "href": "SST_02_timeseries.html#fonctions-de-calcul-de-moyenne-pondérée",
    "title": "\n3  Données temporelles\n",
    "section": "\n3.4 fonctions de calcul de moyenne pondérée",
    "text": "3.4 fonctions de calcul de moyenne pondérée\nLe principe consiste à détecter un fichier de moyenne (fichier RDS) déjà présent ou pas.\nSi ce dernier est présent il est lu et complété.\nDans le cas contraire la constition de ce fichier est réalisée à partir de tous les fichiers NetCDF contenus dans le répertoire DATA.\nSi le fichier pris en compte est un fichier temporaire (suffixe _preliminary) on attribuera à la donnée un status_ok de valeur \\(FALSE\\)\nSi le fichier pris en compte est un fichier finalisé status_okvaudra \\(TRUE\\)\n\n# get weighted mean of one variable between lat_min and lat_max\nget_var_weighted_mean &lt;- function(file, var, lon_min, lon_max, lat_min, lat_max) {\n  # are we consider preliminary file\n  status_ok &lt;- if_else(str_detect(file, '_preliminary'), FALSE, TRUE)\n  #--- get data from NetCDF file\n  nc &lt;- nc_open(file)\n  lon &lt;- ncvar_get(nc, varid = \"lon\")\n  lat &lt;- ncvar_get(nc, varid = \"lat\")\n  time &lt;- ncvar_get(nc, varid = \"time\")\n  var &lt;- ncvar_get(nc, varid = var)\n  nc_close(nc)\n  #--- create the area_weights matrix\n  w &lt;- matrix(rep(area_weights, 1440), ncol = 720, byrow = TRUE)\n  x_min &lt;- min(which(lon &gt;= lon_min))\n  x_max &lt;- max(which(lon &lt;= lon_max))\n  y_min &lt;- min(which(lat &gt;= lat_min))\n  y_max &lt;- max(which(lat &lt;= lat_max))\n  \n  #--- calculate weighted mean\n  wm_var &lt;- weighted.mean(\n    var[x_min:x_max, y_min:y_max], \n    w[x_min:x_max, y_min:y_max], \n    na.rm = TRUE\n  )\n  #--- \n  c(time, wm_var, status_ok)\n}\n\n# get all weighted mean for one variable for all NetCDF files available\nget_var_all_weighted_mean &lt;- function(var, geo_data) {\n  files &lt;- list.files(path = \"DATA\", pattern = \"*.nc\", full.names = TRUE)\n  if (length(files) &gt; 0 ) {\n    lon_min &lt;- geo_data$bbox[\"lon_min\"]\n    lon_max &lt;- geo_data$bbox[\"lon_max\"]\n    lat_min &lt;- geo_data$bbox[\"lat_min\"]\n    lat_max &lt;- geo_data$bbox[\"lat_max\"]\n    #--- RDS file format : wm_&lt;var&gt;_&lt;RDS_name&gt;.RDS\n    RDS_file &lt;- paste0('wm_', var, '_', geo_data$RDS_name, '.RDS')\n    #message(RDS_file)\n    if (file.exists(RDS_file)) {\n      #--- return valid files which mean have already been treated\n      RDS_data &lt;- readRDS(RDS_file) |&gt; \n        filter(status_ok) # élimination des données temporaires\n      saveRDS(RDS_data, RDS_file) \n      valid_files_already_treated &lt;- RDS_data |&gt;\n        pull(date) |&gt; \n        yyyymmdd() |&gt; \n        vapply(\\(x) paste0('DATA/oisst-avhrr-v02r01.', x, '.nc'), character(1))\n      #--- return tempo files which mean have already been treated\n      files_to_treat &lt;- files[!(files %in% valid_files_already_treated)]\n    } else {\n      files_to_treat &lt;- files\n    }\n    #--- be aware not to consider old tempo files for later version !!!\n    origin_date &lt;- ymd(\"1978-01-01\")\n    wm_matrix &lt;- matrix(numeric(0), nrow = length(files_to_treat), ncol = 3)\n    colnames(wm_matrix) &lt;- c('time', 'wm', 'status_ok')\n    for (i in seq_along(files_to_treat)) { \n      result &lt;- get_var_weighted_mean(files_to_treat[i], var, lon_min, lon_max, lat_min, lat_max)\n      #message(paste0(\"file : \", files_to_treat[i]))\n      wm_matrix[i, 1] &lt;- result[1] # time in days from origin date\n      wm_matrix[i, 2] &lt;- result[2] # weighted mean\n      wm_matrix[i, 3] &lt;- result[3] # status\n    }\n    df_wm_var &lt;- as_tibble(wm_matrix) |&gt;\n      set_names('time', paste0('wm_', var), 'status_ok') |&gt; \n      mutate(\n        date = lubridate::as_date(time, origin = origin_date),\n        status_ok = as.logical(status_ok)\n      )\n    if (file.exists(RDS_file)) {\n      RDS_data &lt;- rbind(RDS_data, df_wm_var)\n    } else {\n      RDS_data &lt;- df_wm_var\n    }\n    saveRDS(RDS_data, RDS_file)\n    RDS_data\n  } else { \n    message(\"aucun fichier de données à traiter\") \n  }\n}",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Données temporelles</span>"
    ]
  },
  {
    "objectID": "SST_02_timeseries.html#calcul-des-moyennes-pondérées-pour-le-monde-60s-60n",
    "href": "SST_02_timeseries.html#calcul-des-moyennes-pondérées-pour-le-monde-60s-60n",
    "title": "\n3  Données temporelles\n",
    "section": "\n3.5 calcul des moyennes pondérées pour le monde (60°S-60°N)",
    "text": "3.5 calcul des moyennes pondérées pour le monde (60°S-60°N)\nLes moyennes pondérées sont calculées consécutivement sur les variables sst, anom, et ice.\n\n# get weighted mean var with -60 &lt; latitude &lt; 60\n\ngeo_world &lt;- list(\n  RDS_name = \"world\", \n  bbox = c(lon_min = 0, lon_max = 360, lat_min = -60, lat_max = 60)\n)\n\ndf_wm_sst_world &lt;- get_var_all_weighted_mean(\"sst\", geo_world)\n# df_wm_anom_world &lt;- get_var_all_weighted_mean(\"anom\", geo_world)\n# df_wm_anom_ice &lt;- get_var_all_weighted_mean(\"ice\", geo_world)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Données temporelles</span>"
    ]
  },
  {
    "objectID": "SST_02_timeseries.html#calcul-des-moyennes-pondérées-pour-latlantique-nord-0-60n-0-80w",
    "href": "SST_02_timeseries.html#calcul-des-moyennes-pondérées-pour-latlantique-nord-0-60n-0-80w",
    "title": "\n3  Données temporelles\n",
    "section": "\n3.6 calcul des moyennes pondérées pour l’Atlantique Nord (0-60°N, 0-80W)",
    "text": "3.6 calcul des moyennes pondérées pour l’Atlantique Nord (0-60°N, 0-80W)\nLes mêmes variables que précédemment sont prises en compte.\n\ngeo_north_atlantic &lt;- list(\n  RDS_name = \"north_atlantic\",\n  bbox = c(lon_min = 280, lon_max = 360, lat_min = 0, lat_max = 60)\n)\n\ndf_wm_sst_north_atlantic &lt;- get_var_all_weighted_mean(\"sst\", geo_north_atlantic)\n# df_wm_anom_north_atlantic &lt;- get_var_all_weighted_mean(\"anom\", geo_north_atlantic)\n# df_wm_ice_north_atlantic &lt;- get_var_all_weighted_mean(\"ice\", geo_north_atlantic)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Données temporelles</span>"
    ]
  },
  {
    "objectID": "SST_02_timeseries.html#impression-de-la-série-temporelle",
    "href": "SST_02_timeseries.html#impression-de-la-série-temporelle",
    "title": "\n3  Données temporelles\n",
    "section": "\n3.7 Impression de la série temporelle",
    "text": "3.7 Impression de la série temporelle\n\ndf_wm_sst &lt;- readRDS('wm_sst_world.RDS') |&gt; \n  mutate(\n    year = year(date),\n    yday = yday(date),\n    month = month(date)\n    ) \n\nggplot(data = df_wm_sst,\n       aes(x = yday, y = wm_sst, group = year)) +\n  geom_line(aes(color = factor(year))) +\n  scale_color_grey(start = 0.8, end = 0.2) +\n  geom_line(\n    data = df_wm_sst |&gt; filter(year == 2023),\n    aes(x = yday, y = wm_sst),\n    color = \"orange\",\n    linewidth = 1) +\n  geom_line(\n    data = df_wm_sst |&gt; filter(year == 2024),\n    aes(x = yday, y = wm_sst, group = year),\n    color = \"black\", \n    linewidth = 1) +\n  labs(\n    title = \"Daily Sea Surface Temperature, World (60°S-60°N, 0-360°E)\",\n    subtitle = \"Dataset: NOAA OISST V2.1\",\n    caption = 'caption test',\n    color = NULL,\n    x = NULL,\n    y = NULL\n  ) -&gt; p\n\np + \n  theme_bw() +\n  theme(\n    legend.position = \"bottom\",\n    plot.caption = element_text(margin = margin(t = 0, unit = 'cm')),\n    legend.spacing.x = unit(0.5, 'cm'),\n    legend.key = element_blank(),\n    legend.text = element_text(colour = 'black'),\n  ) +\n  guides(\n    color = guide_legend(\n      ncol = 7, \n      byrow = TRUE, \n      reverse = FALSE,\n      label = TRUE,\n      #label.hjust = 1,\n      #keywidth = unit(0.8, 'cm'),\n      label.position = \"right\",\n      x.intersp = 0.2,\n      text.width = 0.045\n    )\n  )",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Données temporelles</span>"
    ]
  },
  {
    "objectID": "SST_02_timeseries.html#impression-supplémentaire-1",
    "href": "SST_02_timeseries.html#impression-supplémentaire-1",
    "title": "\n3  Données temporelles\n",
    "section": "\n3.8 impression supplémentaire 1",
    "text": "3.8 impression supplémentaire 1\n\nggplot(data = df_wm_sst,\n       aes(x = date, y = wm_sst)) +\n  geom_line() +\n  geom_smooth(\n    method = \"lm\",\n    se = FALSE\n  ) + \n  geom_smooth(\n    data = df_wm_sst |&gt; \n      filter(year &gt; 2000),\n    method = \"lm\",\n    se = FALSE, colour = \"#FFA050\"\n  ) +\n  geom_smooth(\n    data = df_wm_sst |&gt; \n      filter(year &gt; 2010),\n    method = \"lm\",\n    se = FALSE, colour = \"#FF0000\"\n  )\n\n`geom_smooth()` using formula = 'y ~ x'\n`geom_smooth()` using formula = 'y ~ x'\n`geom_smooth()` using formula = 'y ~ x'",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Données temporelles</span>"
    ]
  },
  {
    "objectID": "SST_02_timeseries.html#impression-supplémentaire-2",
    "href": "SST_02_timeseries.html#impression-supplémentaire-2",
    "title": "\n3  Données temporelles\n",
    "section": "\n3.9 impression supplémentaire 2",
    "text": "3.9 impression supplémentaire 2\n\ndf_wm_sst &lt;- readRDS(\"wm_sst_world.RDS\") |&gt; \n  mutate(year = year(date))\nggplot(data = df_wm_sst) +\n  geom_line(aes(x = date, y = wm_sst, group = year, color = year))",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Données temporelles</span>"
    ]
  },
  {
    "objectID": "SST_03_levelplot.html",
    "href": "SST_03_levelplot.html",
    "title": "\n4  Données SST du 21 novembre 2024\n",
    "section": "",
    "text": "4.1 Exploration du fichier NetCDF (comme décrit ici)\nlibs &lt;- c(\n  \"ncdf4\",\n  \"tidyverse\",\n  \"terra\",\n  \"sf\"\n)\n\n#install missing libraries\ninstalled_libs &lt;- libs %in% rownames(installed.packages())\nif (any(installed_libs == FALSE)) {\n  install.packages(libs[!installed_libs])\n}\n\n#load libraries\ninvisible(lapply(libs, library, character.only = TRUE))\nLa connexion au fichier NetCDF s’opère via la commande nc_open.\nGrâce à elle nous pouvons déjà voir quel type d’informations sont enregistrées.\n(nc &lt;- nc_open(\"DATA/oisst-avhrr-v02r01.20241121.nc\"))\n\nFile DATA/oisst-avhrr-v02r01.20241121.nc (NC_FORMAT_NETCDF4):\n\n     4 variables (excluding dimension variables):\n        short sst[lon,lat,zlev,time]   (Chunking: [1440,720,1,1])  (Compression: shuffle,level 4)\n            long_name: Daily sea surface temperature\n            units: Celsius\n            _FillValue: -999\n            add_offset: 0\n            scale_factor: 0.00999999977648258\n            valid_min: -300\n            valid_max: 4500\n        short anom[lon,lat,zlev,time]   (Chunking: [1440,720,1,1])  (Compression: shuffle,level 4)\n            long_name: Daily sea surface temperature anomalies\n            units: Celsius\n            _FillValue: -999\n            add_offset: 0\n            scale_factor: 0.00999999977648258\n            valid_min: -1200\n            valid_max: 1200\n        short err[lon,lat,zlev,time]   (Chunking: [1440,720,1,1])  (Compression: shuffle,level 4)\n            long_name: Estimated error standard deviation of analysed_sst\n            units: Celsius\n            _FillValue: -999\n            add_offset: 0\n            scale_factor: 0.00999999977648258\n            valid_min: 0\n            valid_max: 1000\n        short ice[lon,lat,zlev,time]   (Chunking: [1440,720,1,1])  (Compression: shuffle,level 4)\n            long_name: Sea ice concentration\n            units: %\n            _FillValue: -999\n            add_offset: 0\n            scale_factor: 0.00999999977648258\n            valid_min: 0\n            valid_max: 100\n\n     4 dimensions:\n        time  Size:1   *** is unlimited *** \n            long_name: Center time of the day\n            units: days since 1978-01-01 12:00:00\n        zlev  Size:1 \n            long_name: Sea surface height\n            units: meters\n            positive: down\n            actual_range: 0, 0\n        lat  Size:720 \n            long_name: Latitude\n            units: degrees_north\n            grids: Uniform grid from -89.875 to 89.875 by 0.25\n        lon  Size:1440 \n            long_name: Longitude\n            units: degrees_east\n            grids: Uniform grid from 0.125 to 359.875 by 0.25\n\n    37 global attributes:\n        Conventions: CF-1.6, ACDD-1.3\n        title: NOAA/NCEI 1/4 Degree Daily Optimum Interpolation Sea Surface Temperature (OISST) Analysis, Version 2.1 - Final\n        references: Reynolds, et al.(2007) Daily High-Resolution-Blended Analyses for Sea Surface Temperature (available at https://doi.org/10.1175/2007JCLI1824.1). Banzon, et al.(2016) A long-term record of blended satellite and in situ sea-surface temperature for climate monitoring, modeling and environmental studies (available at https://doi.org/10.5194/essd-8-165-2016). Huang et al. (2020) Improvements of the Daily Optimum Interpolation Sea Surface Temperature (DOISST) Version v02r01, submitted.Climatology is based on 1971-2000 OI.v2 SST. Satellite data: Pathfinder AVHRR SST, Navy AVHRR SST, and NOAA ACSPO SST. Ice data: NCEP Ice and GSFC Ice.\n        source: ICOADS, NCEP_GTS, GSFC_ICE, NCEP_ICE, Pathfinder_AVHRR, Navy_AVHRR, NOAA_ACSP\n        id: oisst-avhrr-v02r01.20241121.nc\n        naming_authority: gov.noaa.ncei\n        summary: NOAAs 1/4-degree Daily Optimum Interpolation Sea Surface Temperature (OISST) (sometimes referred to as Reynolds SST, which however also refers to earlier products at different resolution), currently available as version v02r01, is created by interpolating and extrapolating SST observations from different sources, resulting in a smoothed complete field. The sources of data are satellite (AVHRR) and in situ platforms (i.e., ships and buoys), and the specific datasets employed may change over time. At the marginal ice zone, sea ice concentrations are used to generate proxy SSTs.  A preliminary version of this file is produced in near-real time (1-day latency), and then replaced with a final version after 2 weeks. Note that this is the AVHRR-ONLY DOISST, available from Oct 1981, but there is a companion DOISST product that includes microwave satellite data, available from June 2002\n        cdm_data_type: Grid\n        history: Final file created using preliminary as first guess, and 3 days of AVHRR data. Preliminary uses only 1 day of AVHRR data.\n        date_modified: 2024-12-06T14:44:00Z\n        date_created: 2024-12-06T14:44:00Z\n        product_version: Version v02r01\n        processing_level: NOAA Level 4\n        institution: NOAA/National Centers for Environmental Information\n        creator_url: https://www.ncei.noaa.gov/\n        creator_email: oisst-help@noaa.gov\n        keywords: Earth Science &gt; Oceans &gt; Ocean Temperature &gt; Sea Surface Temperature\n        keywords_vocabulary: Global Change Master Directory (GCMD) Earth Science Keywords\n        platform: Ships, buoys, Argo floats, MetOp-A, MetOp-B\n        platform_vocabulary: Global Change Master Directory (GCMD) Platform Keywords\n        instrument: Earth Remote Sensing Instruments &gt; Passive Remote Sensing &gt; Spectrometers/Radiometers &gt; Imaging Spectrometers/Radiometers &gt; AVHRR &gt; Advanced Very High Resolution Radiometer\n        instrument_vocabulary: Global Change Master Directory (GCMD) Instrument Keywords\n        standard_name_vocabulary: CF Standard Name Table (v40, 25 January 2017)\n        geospatial_lat_min: -90\n        geospatial_lat_max: 90\n        geospatial_lon_min: 0\n        geospatial_lon_max: 360\n        geospatial_lat_units: degrees_north\n        geospatial_lat_resolution: 0.25\n        geospatial_lon_units: degrees_east\n        geospatial_lon_resolution: 0.25\n        time_coverage_start: 2024-11-21T00:00:00Z\n        time_coverage_end: 2024-11-21T23:59:59Z\n        metadata_link: https://doi.org/10.25921/RE9P-PT57\n        ncei_template_version: NCEI_NetCDF_Grid_Template_v2.0\n        comment: Data was converted from NetCDF-3 to NetCDF-4 format with metadata updates in November 2017.\n        sensor: Thermometer, AVHRR",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Un fichier SST</span>"
    ]
  },
  {
    "objectID": "SST_03_levelplot.html#exploration-du-fichier-netcdf-comme-décrit-ici",
    "href": "SST_03_levelplot.html#exploration-du-fichier-netcdf-comme-décrit-ici",
    "title": "\n4  Données SST du 21 novembre 2024\n",
    "section": "",
    "text": "4.1.1 Les dimensions\nles variables principales sont discriminées suivant plusieurs dimensions.\nIci, ce sont :\n\nlon : la longitude (de taille \\(1440=\\frac{360}{0.25}\\))\nlat : la latitude (de taille \\(720=\\frac{180}{0.25}\\))\nzlev : La hauteur de la surface de l’eau de mer\ntime : temps central de la journée\n\n\n\n\n\n\n\nNote\n\n\n\n\n\n\nLes longitudes sont ordonnées de l’Est vers l’Ouest en partant du méridien de Greenwich depuis la valeur \\(0.125\\) jusqu’à la valeur \\(0.125+1439*0.25=359.875\\)\nLes latitudes sont ordonnées du Sud au Nord dans l’array lat en partant du pôle Sud depuis la valeur \\(-90+0.125=-89.875\\) jusqu’à la valeur \\(-89.875+719*0.25=89.875\\)\n\n\n\n\nIl est possible d’avoir accès aux données des dimensions via la fonction ncvar_get et l’accès aux attributs avec la fonction ncatt_get\n\n# get info about latitudes\nlat &lt;- ncvar_get(nc, \"lat\")\n(lat_units &lt;- ncatt_get(nc, \"lat\", \"units\"))\n\n$hasatt\n[1] TRUE\n\n$value\n[1] \"degrees_north\"\n\n# get info about longitudes\nlon &lt;- ncvar_get(nc, \"lon\")\n(lon_units &lt;- ncatt_get(nc, \"lon\", \"units\"))\n\n$hasatt\n[1] TRUE\n\n$value\n[1] \"degrees_east\"\n\n# get info about time\ntime &lt;- ncvar_get(nc, \"time\")\n(time_units &lt;- ncatt_get(nc, \"time\", \"units\"))\n\n$hasatt\n[1] TRUE\n\n$value\n[1] \"days since 1978-01-01 12:00:00\"\n\ntime_as_date &lt;- as.Date(time, origin = \"1978-01-01 12:00:0\", tz = \"UTC\")\n# get info about zlev\nzlev &lt;- ncvar_get(nc, \"zlev\")\n(zlev_units &lt;- ncatt_get(nc, \"zlev\", \"units\"))\n\n$hasatt\n[1] TRUE\n\n$value\n[1] \"meters\"\n\n\n\n4.1.2 Les variables principales\nNous avons quatre variables stockées dans le fichier :\n\nsst : la température quotidienne de la surface de l’eau\nanom : les anomalies quotidiennes de température de surface de l’eau\nerr : estimated error standard deviation of analysed_sst\nice : la concentration en glace\n\n\n(nc_var &lt;- names(nc$var))\n\n[1] \"sst\"  \"anom\" \"err\"  \"ice\" \n\n# get info about variable attribute\nget_var_attribute &lt;- function(var, attribute) {\n  nc_var &lt;- names(nc$var)\n  if (!(var %in% nc_var)) {\n    message(paste(\"la variable\", var, \"est inexistante\"))\n  } else {\n  ln &lt;- ncatt_get(nc, var, attname = attribute)\n  ifelse(ln$hasatt, ln$value, paste(\"pas d'attribut \", attribute))\n  }\n}\n\n# long names\nget_var_long_name &lt;- function() {\n  vapply(\n  nc_var, \n  get_var_attribute, \n  FUN.VALUE = character(1), \n  \"long_name\"\n  )\n}\n((get_var_long_name()))\n\n                                                 sst \n                     \"Daily sea surface temperature\" \n                                                anom \n           \"Daily sea surface temperature anomalies\" \n                                                 err \n\"Estimated error standard deviation of analysed_sst\" \n                                                 ice \n                             \"Sea ice concentration\" \n\n# source\nget_var_units &lt;- function() {\n  vapply(\n  nc_var, \n  get_var_attribute, \n  FUN.VALUE = character(1), \n  \"units\"\n  )\n}\n((get_var_units()))\n\n      sst      anom       err       ice \n\"Celsius\" \"Celsius\" \"Celsius\"       \"%\" \n\n# fill value\nget_var_fill_value &lt;- function() {\n  vapply(\n  nc_var, \n  get_var_attribute, \n  FUN.VALUE = numeric(1), \n  \"_FillValue\"\n  )\n}\n((get_var_fill_value()))\n\n sst anom  err  ice \n-999 -999 -999 -999 \n\n\n\n4.1.3 Les attributs globaux du fichier\n\natt &lt;- c(\"title\", \"institution\", \"source\", \"references\", \"history\", \"Conventions\") \nget_global_attribute &lt;- function(att) {\n  ncatt_get(nc, 0, att)$value\n}\n(global_attributes &lt;- vapply(att, get_global_attribute, FUN.VALUE = character(1)))\n\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        title \n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \"NOAA/NCEI 1/4 Degree Daily Optimum Interpolation Sea Surface Temperature (OISST) Analysis, Version 2.1 - Final\" \n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  institution \n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \"NOAA/National Centers for Environmental Information\" \n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       source \n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \"ICOADS, NCEP_GTS, GSFC_ICE, NCEP_ICE, Pathfinder_AVHRR, Navy_AVHRR, NOAA_ACSP\" \n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   references \n\"Reynolds, et al.(2007) Daily High-Resolution-Blended Analyses for Sea Surface Temperature (available at https://doi.org/10.1175/2007JCLI1824.1). Banzon, et al.(2016) A long-term record of blended satellite and in situ sea-surface temperature for climate monitoring, modeling and environmental studies (available at https://doi.org/10.5194/essd-8-165-2016). Huang et al. (2020) Improvements of the Daily Optimum Interpolation Sea Surface Temperature (DOISST) Version v02r01, submitted.Climatology is based on 1971-2000 OI.v2 SST. Satellite data: Pathfinder AVHRR SST, Navy AVHRR SST, and NOAA ACSPO SST. Ice data: NCEP Ice and GSFC Ice.\" \n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      history \n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \"Final file created using preliminary as first guess, and 3 days of AVHRR data. Preliminary uses only 1 day of AVHRR data.\" \n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Conventions \n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \"CF-1.6, ACDD-1.3\"",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Un fichier SST</span>"
    ]
  },
  {
    "objectID": "SST_03_levelplot.html#exploration-des-variables",
    "href": "SST_03_levelplot.html#exploration-des-variables",
    "title": "\n4  Données SST du 21 novembre 2024\n",
    "section": "\n4.2 Exploration des variables",
    "text": "4.2 Exploration des variables\n\nnc_var &lt;- names(nc$var)\n\nnc_charge_var &lt;- function(var) {\n  nc_var &lt;- ncvar_get(nc = nc, varid = var )\n  envir &lt;- globalenv()\n  assign(var, nc_var, envir = envir)\n}\n\nwalk(nc_var, nc_charge_var)\n\nLa variable sst est enregistrée en tant que matrix, array avec les dimensions 1440, 720\n\nLa longitude correspond à la 1ère dimension (lignes de la matrice)\nLa latitude correspond à la 2ème dimension (colonnes de la matrice)\nLe vecteur associé est obtenu en parcourant d’abord les 1440 longitudes d’un parallèle avant de passer à la latitude suivante.\n\n\nlonlat &lt;- expand.grid(lon, lat)\ndf_sst &lt;- cbind(lonlat, as.vector(sst))\nnames(df_sst) &lt;- c(\"lon\", \"lat\", \"sst\")\nhead(df_sst)\n\n    lon     lat sst\n1 0.125 -89.875  NA\n2 0.375 -89.875  NA\n3 0.625 -89.875  NA\n4 0.875 -89.875  NA\n5 1.125 -89.875  NA\n6 1.375 -89.875  NA",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Un fichier SST</span>"
    ]
  },
  {
    "objectID": "SST_03_levelplot.html#affichage-de-la-carte-des-données-sst",
    "href": "SST_03_levelplot.html#affichage-de-la-carte-des-données-sst",
    "title": "\n4  Données SST du 21 novembre 2024\n",
    "section": "\n4.3 Affichage de la carte des données sst",
    "text": "4.3 Affichage de la carte des données sst\nAvec positionnement en rouge du point de test donné en exemple :\n\n#|label: plot_sst\n\ndf_sst |&gt; \n  ggplot(aes(x = lon, y = lat, color = sst)) + \n  geom_point(size = 0.5) +\n  coord_fixed(expand = FALSE) +\n  scale_colour_distiller(palette = \"RdBu\") +\n  labs(\n    x = NULL,\n    y = NULL,\n    title = \"Sea Surface Temperature\",\n    subtitle = time_as_date,\n    caption = \"Dataset: NOAA OISST V2.1\",\n    color = \"°C\"\n  )",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Un fichier SST</span>"
    ]
  },
  {
    "objectID": "SST_03_levelplot.html#calcul-de-moyenne-globale",
    "href": "SST_03_levelplot.html#calcul-de-moyenne-globale",
    "title": "\n4  Données SST du 21 novembre 2024\n",
    "section": "\n4.4 Calcul de moyenne globale",
    "text": "4.4 Calcul de moyenne globale\nIl semble qu’il faille appliquer un poids fonction de \\(\\alpha\\) en radians pour pondérer les mesures de surface en fonction de la latitude considérée.\nPour calculer ces poids j’ai construit tous les polygones “carrés” de 0.25° de côté suivant un même méridien.\nCes polygones ont pour centre les coordonnées (longitude et latitude) de la mesure SST correspondante.\nJ’ai ensuite calculé les aires de ces polygones avec le système de coordonnées de référence EPSG:4326 (WGS84).\nLes poids relatifs à chaque mesure ont été fixés comme étant les ratio des aires obtenues avec celle de la plus grande aire (aire du polygone situé à l’équateur).\n\n4.4.1 Calcul des poids à affecter aux mesures suivant la latitude associée\n\n# fonction génératrice de \"carré géographique\" de n degrés de côté\n# le point de base (lon, lat) est le point inférieur gauche. \n\npolygone_geo &lt;- function(lon, lat, n) {\n  polygon_list &lt;- list(rbind(\n    c(lon, lat),\n    c(lon + n, lat),\n    c(lon + n, lat + n),\n    c(lon, lat + n),\n    c(lon, lat)\n  ))\n  st_polygon(polygon_list)\n}\n\npolygone_sfc &lt;- seq(-90, 89.75, by = 0.25) |&gt;\n  map(\\(x) polygone_geo(lon = 0, lat = x, n = 0.25)) |&gt; \n  st_sfc(crs = \"EPSG:4326\")\n\narea_weights &lt;- as.numeric(st_area(polygone_sfc) / max(st_area(polygone_sfc)))\nhead(area_weights)\n\n[1] 0.002181655 0.006544922 0.010908066 0.015271001 0.019633646 0.023995917\n\n\n\ndf_area_weights &lt;- expand.grid(lon, area_weights)\nnames(df_area_weights) &lt;- c(\"lon\", \"w\")\nw &lt;- df_area_weights$w\ndf_sst_weights &lt;- cbind(df_sst, w)\n\n# moyenne pondérée globale\nsst_weighted_mean &lt;- df_sst_weights |&gt; \n  summarize(wm_sst = weighted.mean(sst, w, na.rm = TRUE))\nsst_weighted_mean\n\n    wm_sst\n1 18.46698\n\n# moyenne pondérée entre -60°S et +60°N\ndf_sst_60S_60N &lt;- df_sst_weights |&gt; \n  filter(lat &gt;= -60 & lat &lt;= 60)\nsst_weighted_mean_60S_60N &lt;- df_sst_60S_60N |&gt; \n  summarize(wm_sst_60S_60N = weighted.mean(sst, w, na.rm = TRUE))\nsst_weighted_mean_60S_60N\n\n  wm_sst_60S_60N\n1       20.67597\n\n\nSi nous souhaitons centrer la carte sur le méridien de Greenwich, il est nécessaire de translater les longitudes.\n\n#|label: plot_sst_greenwich\n\ndf_sst |&gt; \n  mutate(lon = if_else(lon &gt; 180, lon - 360, lon)) |&gt; \n  ggplot(aes(x = lon, y = lat, fill = sst)) + \n  geom_raster() +\n  scale_fill_gradient2(\n    low = \"darkblue\",\n    mid = \"white\",\n    high = \"darkred\",\n    midpoint = 15\n  ) +\n  coord_fixed(expand = FALSE) +\n  #scale_colour_distiller(palette = \"RdBu\") +\n  labs(\n    x = NULL,\n    y = NULL,\n    title = \"Sea Surface Temperature\",\n    subtitle = paste0(\n      time_as_date,\n      \" - mean global = \",\n      round(sst_weighted_mean, 1),\n      \" °Celsius\",\n      \" | \",\n      \" mean World(60°S-60°N) = \",\n      round(sst_weighted_mean_60S_60N, 1),\n      \" °Celsius\"\n    ),\n    caption = \"Dataset: NOAA OISST V2.1\",\n    fill = \"°C\",\n  ) +\n  theme(\n    axis.text = element_blank(),\n    axis.ticks = element_blank(),\n    # panel.background = element_rect(fill = \"black\"),\n    # plot.background = element_rect(fill = \"black\")\n  )",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Un fichier SST</span>"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Fichiers NetCDF",
    "section": "",
    "text": "Preface",
    "crumbs": [
      "Preface"
    ]
  }
]